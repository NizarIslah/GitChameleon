
{"python_version": "3.9", "library": "plotly", "version": "3.0.0", "problem": "Define a function named custom_scatter that accepts a color value as an argument and uses Plotly\u2019s graph objects to create a figure containing a scatter plot with a single point at coordinates (0, 0). The marker for this point should use the provided color. Finally, the function should return the created figure.", "starting_code": "import plotly.graph_objs as go\n\ndef custom_scatter(custom_color):\n    return ", "example_id": "275", "test": "color = 'rgb(255,45,15)'\nimport warnings\n\nwith warnings.catch_warnings(record=True) as w:\n    warnings.simplefilter(\"always\")\n    fig = custom_scatter(color)\n    for warn in w:\n        assert not issubclass(warn.category, DeprecationWarning), \"Deprecated API used!\"\n\nscatter_trace = fig.data[0]\nmarker_color = scatter_trace.marker.color\nexpect = color\nassert marker_color == expect", "solution": "go.Figure(data=[go.Scatter(x=[0],y=[0],marker=go.scatter.Marker(color=custom_color)) ])", "type_of_change": "argument change", "name_of_class_or_func": "plotly.graph_objs.Scatter()", "additional_dependencies": ""}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to compute the dynamic time warp between arrays X and Y. ", "starting_code": "import numpy as np\nimport librosa\nfrom scipy.spatial.distance import cdist\n\ndef compute_dtw(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n    \n", "example_id": "276", "test": "\nX = np.array([[1, 3, 3, 8, 1]])\nY = np.array([[2, 0, 0, 8, 7, 2]])\n\ngt_D = np.array([[1., 2., 3., 10., 16., 17.],\n [2., 4., 5., 8., 12., 13.],\n [3., 5., 7., 10., 12., 13.],\n [9., 11., 13., 7., 8., 14.],\n [10, 10., 11., 14., 13., 9.]])\nassert np.array_equal(gt_D, compute_dtw(X, Y))", "solution": "\n\n    dist_matrix = cdist(X.T, Y.T, metric='euclidean')\n    return librosa.dtw(C=dist_matrix, metric='invalid')[0]", "type_of_change": "name change", "name_of_class_or_func": "librosa.dtw", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute the dynamic time warp between arrays X and Y. ", "starting_code": "import numpy as np\nimport librosa\nfrom scipy.spatial.distance import cdist\n\ndef compute_dtw(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n    \n", "example_id": "277", "test": "\nX = np.array([[1, 3, 3, 8, 1]])\nY = np.array([[2, 0, 0, 8, 7, 2]])\n\ngt_D = np.array([[1., 2., 3., 10., 16., 17.],\n [2., 4., 5., 8., 12., 13.],\n [3., 5., 7., 10., 12., 13.],\n [9., 11., 13., 7., 8., 14.],\n [10, 10., 11., 14., 13., 9.]])\nassert np.array_equal(gt_D, compute_dtw(X, Y))", "solution": "\n\n    dist_matrix = cdist(X.T, Y.T, metric='euclidean')\n    return librosa.sequence.dtw(C=dist_matrix, metric='invalid')[0]", "type_of_change": "name change", "name_of_class_or_func": "librosa.sequence.dtw", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to compute the root mean square value for each frame. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_rms(y: np.ndarray) -> np.float32:\n    ", "example_id": "278", "test": "\nduration = 2.0 \nfrequency = 440 \nsr = 22050 \n\nt = np.linspace(0, duration, int(sr * duration), endpoint=False)\n\ny = 0.5 * np.sin(2 * np.pi * frequency * t)\n\nassert np.array_equal(librosa.feature.rmse(y=y), compute_rms(y))", "solution": "\n\n    return librosa.feature.rmse(y=y)", "type_of_change": "name change", "name_of_class_or_func": "librosa.feature.rmse", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute the root mean square value for each frame. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_rms(y: np.ndarray) -> np.float32:\n    ", "example_id": "279", "test": "\nduration = 2.0 \nfrequency = 440 \nsr = 22050 \n\nt = np.linspace(0, duration, int(sr * duration), endpoint=False)\n\ny = 0.5 * np.sin(2 * np.pi * frequency * t)\n\nassert np.array_equal(librosa.feature.rms(y=y), compute_rms(y))", "solution": "\n\n    return librosa.feature.rms(y=y)", "type_of_change": "name change", "name_of_class_or_func": "librosa.feature.rms", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to fill the off diagonal with a value of 0 with the constraint region being a Sakoe-Chiba band of radius 0.25. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_fill_diagonal(mut_x: np.ndarray, radius: float) -> np.ndarray:\n    ", "example_id": "280", "test": "\nmut_x = np.ones((8, 12))\nradius = 0.25\n\nassert np.array_equal(librosa.fill_off_diagonal(mut_x,  radius), compute_fill_diagonal(mut_x, radius))", "solution": "\n\n    return librosa.fill_off_diagonal(mut_x,  radius)", "type_of_change": "name change", "name_of_class_or_func": "librosa.fill_off_diagonal", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to fill the off diagonal with a value of 0 with the constraint region being a Sakoe-Chiba band of radius 0.25. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_fill_diagonal(mut_x: np.ndarray, radius: float) -> np.ndarray:\n    ", "example_id": "281", "test": "\nmut_x = np.ones((8, 12))\nradius = 0.25\n\nassert np.array_equal(librosa.util.fill_off_diagonal(mut_x,  radius), compute_fill_diagonal(mut_x, radius))", "solution": "\n\n    return librosa.util.fill_off_diagonal(mut_x,  radius)", "type_of_change": "name change", "name_of_class_or_func": "librosa.util.fill_off_diagonal", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to extract melspectrogram from waveform y. After it is computed, determine if it is of type float64. Return both values as a tuple.", "starting_code": "import librosa\nimport numpy as np\nfrom typing import Tuple\n\ndef compute_extraction(y: np.ndarray, sr: int) -> Tuple[np.ndarray, bool]:\n    ", "example_id": "282", "test": "\nduration = 2.0 \nfrequency = 440\nsr = 22050 \n\nt = np.linspace(0, duration, int(sr * duration), endpoint=False)\n\ny = 0.5 * np.sin(2 * np.pi * frequency * t)\ny = y.astype(np.float32)\n\nsol=librosa.feature.melspectrogram(y=y, sr=sr) \nM_from_y, float64_bool = compute_extraction(y, sr)\nassert np.array_equal(sol, M_from_y)\nassert float64_bool \n\n", "solution": "\n\n    M_from_y = librosa.feature.melspectrogram(y=y, sr=sr) \n    return M_from_y, M_from_y.dtype == np.float64", "type_of_change": "behaviour", "name_of_class_or_func": "librosa.feature.melspectrogram", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to extract melspectrogram from waveform y. After it is computed, determine if it is of type float32.", "starting_code": "import librosa\nimport numpy as np\nfrom typing import Tuple\n\ndef compute_extraction(y: np.ndarray, sr: int) -> Tuple[np.ndarray, bool]:\n    ", "example_id": "283", "test": "\nduration = 2.0 \nfrequency = 440 \nsr = 22050 \nt = np.linspace(0, duration, int(sr * duration), endpoint=False)\n\ny = 0.5 * np.sin(2 * np.pi * frequency * t)\ny = y.astype(np.float32)\n\nsol=librosa.feature.melspectrogram(y=y, sr=sr) \nM_from_y, float32_bool = compute_extraction(y, sr)\nassert np.array_equal(sol, M_from_y)\nassert float32_bool\n", "solution": "\n\n    M_from_y = librosa.feature.melspectrogram(y=y, sr=sr) \n    return M_from_y, M_from_y.dtype == np.float32\n", "type_of_change": "behaviour", "name_of_class_or_func": "librosa.feature.melspectrogram", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to iterate over an audio file using a stream and calculate the STFT on each mono channel.", "starting_code": "import librosa\nimport numpy as np\nimport soundfile as sf \n\n\n# Save the stream in variable stream. Save each stream block with the array stream_blocks\ndef compute_stream(y, sr, n_fft, hop_length):\n    stream_blocks = []", "example_id": "284", "test": "\n\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\n\nn_fft = 4096\nhop_length = n_fft // 2\n\nstream, stream_blocks = compute_stream(y, sr, n_fft, hop_length)\nsol_stream = sf.blocks(filename, blocksize=n_fft + 15 * hop_length, overlap=n_fft - hop_length, fill_value=0)\nsol_blocks = []\nfor c, block in enumerate(sol_stream):\n    y = librosa.to_mono(block.T)\n    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, center=False)\n    sol_blocks.append(D)\nfor i in range(0, len(stream_blocks)):\n    assert np.array_equal(sol_blocks[i], stream_blocks[i])", "solution": "\n\n    stream = sf.blocks(filename, blocksize=n_fft + 15 * hop_length, overlap=n_fft - hop_length,  fill_value=0)\n\n    for c, block in enumerate(stream):\n        y = librosa.to_mono(block.T)\n        D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, center=False)\n        stream_blocks.append(D)\n\n    return stream, stream_blocks", "type_of_change": "new feature", "name_of_class_or_func": "soundfile.blocks", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to complete the function to iterate over an audio file using a stream and calculate the STFT on each mono channel. Frame_length is given by n_fft. Save the stream and each stream block.", "starting_code": "import librosa\nimport numpy as np\n\n# Save the stream in variable stream. Save each stream block with the array stream_blocks\ndef compute_stream(y, sr, n_fft, hop_length):\n    stream_blocks = []", "example_id": "285", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\n\nn_fft = 4096\nhop_length = n_fft // 2\nstream, stream_blocks = compute_stream(y, sr, n_fft, hop_length)\nsol_stream =  librosa.stream(filename, block_length=16,\n                        frame_length=n_fft,\n                        hop_length=hop_length,\n                        mono=True,\n                        fill_value=0)\nfor c, y_block in enumerate(sol_stream):\n    assert  np.array_equal(librosa.stft(y_block, n_fft=n_fft, hop_length=hop_length, center=False), stream_blocks[c])", "solution": "\n\n\n    stream =  librosa.stream(filename, block_length=16,\n                        frame_length=n_fft,\n                        hop_length=hop_length,\n                        mono=True,\n                        fill_value=0)\n\n    for c, y_block in enumerate(stream):\n        stream_blocks.append(librosa.stft(y_block, n_fft=n_fft, hop_length=hop_length, center=False))\n    return stream, stream_blocks", "type_of_change": "new feature", "name_of_class_or_func": "librosa.stream", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Compute an approximate magnitude spectrogram inversion using the Griffin-Lim algorithm.", "starting_code": "import librosa\nimport numpy as np\nfrom librosa import istft, stft\nfrom typing import Union, Optional\n\nDTypeLike = Union[np.dtype, type]\n\ndef compute_griffinlim(y: np.ndarray, sr: int, S: np.ndarray, random_state: int, n_iter: int, hop_length: Optional[int], win_length: Optional[int], window: str, center: bool, dtype: DTypeLike, length: Optional[int], pad_mode: str, n_fft: int) -> np.ndarray:\n    \"\"\"\n    Compute waveform from a linear scale magnitude spectrogram using the Griffin-Lim transformation.\n\n    Parameters:\n    y: Audio timeseries.\n    sr: Sampling rate.\n    S: short-time Fourier transform magnitude matrix.\n    random_state: Random state for the random number generator.\n    n_iter: Number of iterations.\n    hop_length: Hop length.\n    win_length: Window length.\n    window: Window function.\n    center: If True, the signal y is padded so that frame t is centered at y[t * hop_length]. If False, then frame t begins at y[t * hop_length].\n    dtype: Data type of the output.\n    length: Length of the output signal.\n    pad_mode: Padding mode.\n    n_fft: FFT size.\n\n    Returns:\n        The Griffin-Lim waveform.        \n    \"\"\"\n    rng = np.random.RandomState(seed=random_state)\n", "example_id": "286", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nmomentum = 0.99\nS = np.abs(librosa.stft(y))\nrandom_state = 0\nrng = np.random.RandomState(seed=random_state)\nn_iter=32\nhop_length=None\nwin_length=None\nwindow='hann'\ncenter=True\ndtype=np.float32\nlength=None\npad_mode='reflect'\nn_fft = 2 * (S.shape[0] - 1)\n\nrng = np.random.RandomState(seed=random_state)\nsol = compute_griffinlim(y, sr, S, random_state, n_iter, hop_length, win_length, window, center, dtype, length, pad_mode, n_fft)\n\nrng = np.random.RandomState(seed=random_state)\nangles = np.exp(2j * np.pi * rng.rand(*S.shape))\n\nrebuilt = 0.\n\nfor _ in range(n_iter):\n    tprev = rebuilt\n\n    inverse = istft(S * angles, hop_length=hop_length, win_length=win_length,\n    window=window, center=center, dtype=dtype, length=length)\n\n    rebuilt = stft(inverse, n_fft=n_fft, hop_length=hop_length,\n    win_length=win_length, window=window, center=center,\n    pad_mode=pad_mode)\n\n    angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n    angles[:] /= np.abs(angles) + 1e-16\n\ntest_sol = istft(S * angles, hop_length=hop_length, win_length=win_length,window=window, center=center, dtype=dtype, length=length)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    angles = np.exp(2j * np.pi * rng.rand(*S.shape))\n    \n    rebuilt = 0.\n    \n    for _ in range(n_iter):\n        tprev = rebuilt\n    \n        inverse = istft(S * angles, hop_length=hop_length, win_length=win_length,\n        window=window, center=center, dtype=dtype, length=length)\n    \n        rebuilt = stft(inverse, n_fft=n_fft, hop_length=hop_length,\n        win_length=win_length, window=window, center=center,\n        pad_mode=pad_mode)\n    \n        angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n        angles[:] /= np.abs(angles) + 1e-16\n    return istft(S * angles, hop_length=hop_length, win_length=win_length,window=window, center=center, dtype=dtype, length=length)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.griffinlim", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute an approximate magnitude spectrogram inversion using the Griffin-Lim algorithm.", "starting_code": "import librosa\nimport numpy as np\nfrom librosa import istft, stft\nfrom typing import Union, Optional\n\nDTypeLike = Union[np.dtype, type]\n\ndef compute_griffinlim(y: np.ndarray, sr: int, S: np.ndarray, random_state: int, n_iter: int, hop_length: Optional[int], win_length: Optional[int], window: str, center: bool, dtype: DTypeLike, length: Optional[int], pad_mode: str, n_fft: int) -> np.ndarray:\n    \"\"\"\n    Compute waveform from a linear scale magnitude spectrogram using the Griffin-Lim transformation.\n\n    Parameters:\n        y: Audio timeseries.\n        sr: Sampling rate.\n        S: short-time Fourier transform magnitude matrix.\n        random_state: Random state for the random number generator.\n        n_iter: Number of iterations.\n        hop_length: Hop length.\n        win_length: Window length.\n        window: Window function.\n        center: If True, the signal y is padded so that frame t is centered at y[t * hop_length]. If False, then frame t begins at y[t * hop_length].\n        dtype: Data type of the output.\n        length: Length of the output signal.\n        pad_mode: Padding mode.\n        n_fft: FFT size.\n\n    Returns:\n        The Griffin-Lim waveform.        \n    \"\"\"    \n    rng = np.random.RandomState(seed=random_state)\n", "example_id": "287", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nmomentum = 0.99\nS = np.abs(librosa.stft(y))\nrandom_state = 0\nrng = np.random.RandomState(seed=random_state)\nn_iter=32\nhop_length=None\nwin_length=None\nwindow='hann'\ncenter=True\ndtype=np.float32\nlength=None\npad_mode='reflect'\nn_fft = 2 * (S.shape[0] - 1)\n\nsol = compute_griffinlim(y, sr, S, random_state, n_iter, hop_length, win_length, window, center, dtype, length, pad_mode, n_fft)\n\nrng = np.random.RandomState(seed=random_state)\ntest_sol = librosa.griffinlim(S, n_iter, hop_length, win_length, window, center, dtype, length, pad_mode, momentum, random_state)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    return librosa.griffinlim(S, n_iter, hop_length, win_length, window, center, dtype, length, pad_mode, momentum, random_state)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.griffinlim", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to compute Linear Prediction coefficents of input array y.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_lpc_coef(y: np.ndarray, sr: int, order: int) -> np.ndarray:\n    \"\"\"\n    Compute the Linear Prediction Coefficients of an audio signal.\n\n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        order: Order of the linear filter.\n\n    Returns:\n        LP prediction error coefficients, i.e. filter denominator polynomial.\n    \"\"\"\n    ", "example_id": "288", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\norder=2\n\nsol = compute_lpc_coef(y, sr, order)\ndtype = y.dtype.type\nar_coeffs = np.zeros(order+1, dtype=dtype)\nar_coeffs[0] = dtype(1)\nar_coeffs_prev = np.zeros(order+1, dtype=dtype)\nar_coeffs_prev[0] = dtype(1)\nfwd_pred_error = y[1:]\nbwd_pred_error = y[:-1]\nden = np.dot(fwd_pred_error, fwd_pred_error) \\\n      + np.dot(bwd_pred_error, bwd_pred_error)\nfor i in range(order):\n    if den <= 0:\n        raise FloatingPointError('numerical error, input ill-conditioned?')\n    reflect_coeff = dtype(-2) * np.dot(bwd_pred_error, fwd_pred_error) / dtype(den)\n    ar_coeffs_prev, ar_coeffs = ar_coeffs, ar_coeffs_prev\n    for j in range(1, i + 2):\n        ar_coeffs[j] = ar_coeffs_prev[j] + reflect_coeff * ar_coeffs_prev[i - j + 1]\n    fwd_pred_error_tmp = fwd_pred_error\n    fwd_pred_error = fwd_pred_error + reflect_coeff * bwd_pred_error\n    bwd_pred_error = bwd_pred_error + reflect_coeff * fwd_pred_error_tmp\n    q = dtype(1) - reflect_coeff**2\n    den = q*den - bwd_pred_error[-1]**2 - fwd_pred_error[0]**2\n    fwd_pred_error = fwd_pred_error[1:]\n    bwd_pred_error = bwd_pred_error[:-1]\n\ntest_sol = ar_coeffs\nassert np.array_equal(test_sol, sol)", "solution": "\n    \n    dtype = y.dtype.type\n    ar_coeffs = np.zeros(order+1, dtype=dtype)\n    ar_coeffs[0] = dtype(1)\n    ar_coeffs_prev = np.zeros(order+1, dtype=dtype)\n    ar_coeffs_prev[0] = dtype(1)\n    fwd_pred_error = y[1:]\n    bwd_pred_error = y[:-1]\n    den = np.dot(fwd_pred_error, fwd_pred_error) \\\n          + np.dot(bwd_pred_error, bwd_pred_error)\n    for i in range(order):\n        if den <= 0:\n            raise FloatingPointError('numerical error, input ill-conditioned?')\n        reflect_coeff = dtype(-2) * np.dot(bwd_pred_error, fwd_pred_error) / dtype(den)\n        ar_coeffs_prev, ar_coeffs = ar_coeffs, ar_coeffs_prev\n        for j in range(1, i + 2):\n            ar_coeffs[j] = ar_coeffs_prev[j] + reflect_coeff * ar_coeffs_prev[i - j + 1]\n        fwd_pred_error_tmp = fwd_pred_error\n        fwd_pred_error = fwd_pred_error + reflect_coeff * bwd_pred_error\n        bwd_pred_error = bwd_pred_error + reflect_coeff * fwd_pred_error_tmp\n        q = dtype(1) - reflect_coeff**2\n        den = q*den - bwd_pred_error[-1]**2 - fwd_pred_error[0]**2\n        fwd_pred_error = fwd_pred_error[1:]\n        bwd_pred_error = bwd_pred_error[:-1]\n    return ar_coeffs", "type_of_change": "new feature", "name_of_class_or_func": "librosa.lpc", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute Linear Prediction coefficents of input array y.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_lpc_coef(y: np.ndarray, sr: int, order: int) -> np.ndarray:\n    \"\"\"\n    Compute the Linear Prediction Coefficients of an audio signal.\n\n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        order: Order of the linear filter.\n\n    Returns:\n        LP prediction error coefficients, i.e. filter denominator polynomial.\n    \"\"\"\n", "example_id": "289", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\norder=2\n\nsol = compute_lpc_coef(y, sr, order)\ntest_sol = librosa.lpc(y, order)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return librosa.lpc(y, order)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.lpc", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to compute local onset autocorrelation in order to create a fourier tempogram.", "starting_code": "import librosa\nimport numpy as np\nfrom librosa.core.spectrum import stft\n\ndef compute_fourier_tempogram(oenv: np.ndarray, sr: int, hop_length: int) -> np.ndarray:\n    \"\"\"\n    Compute the Fourier tempogram: the short-time Fourier transform of the onset strength envelope.\n\n    Parameters:\n       oenv: The onset strength envelope.\n       sr: The sampling rate of the audio signal in Hertz.\n       hop_length: The number of samples between successive frames.\n\n    Returns:\n       The computed Fourier tempogram.\n    \"\"\"", "example_id": "290", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nhop_length = 512\noenv = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n\nsol = compute_fourier_tempogram(oenv, sr, hop_length)\ntest_sol = stft(oenv, n_fft=384, hop_length=1, center=True, window=\"hann\")\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return stft(oenv, n_fft=384, hop_length=1, center=True, window=\"hann\")", "type_of_change": "new feature", "name_of_class_or_func": "librosa.feature.fourier_tempogram", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute local onset autocorrelation using fourier_tempogram.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_fourier_tempogram(oenv: np.ndarray, sr: int, hop_length: int) -> np.ndarray:\n    \"\"\"\n    Compute the Fourier tempogram: the short-time Fourier transform of the onset strength envelope.\n\n    Parameters:\n       oenv: The onset strength envelope.\n       sr: The sampling rate of the audio signal in Hertz.\n       hop_length: The number of samples between successive frames.\n\n    Returns:\n       The computed Fourier tempogram.\n    \"\"\"\n    ", "example_id": "291", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nhop_length = 512\noenv = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n\nsol = compute_fourier_tempogram(oenv, sr, hop_length)\ntest_sol = librosa.feature.fourier_tempogram(onset_envelope=oenv, sr=sr, hop_length=hop_length)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return librosa.feature.fourier_tempogram(onset_envelope=oenv, sr=sr, hop_length=hop_length)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.feature.fourier_tempogram", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to compute the predominant local pulse (PLP) estimation of y.", "starting_code": "import librosa\nimport numpy as np\nfrom librosa.core.spectrum import stft, istft\nfrom typing import Optional\n\n\ndef compute_plp(\n    y: np.ndarray,\n    sr: int,\n    hop_length: int,\n    win_length: int,\n    tempo_min: Optional[float],\n    tempo_max: Optional[float],\n    onset_env: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    Compute the Predominant Local Pulse (PLP) of an audio signal.\n    \n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        hop_length: The number of samples between successive frames.\n        win_length: The length (in samples) of the analysis window.\n        tempo_min: The minimum tempo (in BPM) for consideration.\n        tempo_max: The maximum tempo (in BPM) for consideration.\n        onset_env: The onset envelope of the audio signal.\n        \n    Returns:\n        The computed PLP (Predominant Local Pulse) values.\n    \"\"\"", "example_id": "292", "test": "filename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nhop_length=512\nwin_length=384\ntempo_min = None\ntempo_max = None\nonset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n\n\nsol = compute_plp(y, sr, hop_length, win_length, tempo_min, tempo_max, onset_env)\n\nftgram = stft(onset_env, n_fft=win_length, hop_length=1, center=True, window=\"hann\")\n\ntempo_frequencies = np.fft.rfftfreq(n=win_length, d=(sr * 60 / float(hop_length)))\n\nftmag = np.abs(ftgram)\npeak_values = ftmag.max(axis=0, keepdims=True)\nftgram[ftmag < peak_values] = 0\n\nftgram[:] /= peak_values\n\npulse = istft(ftgram, hop_length=1, length=len(onset_env))\n\nnp.clip(pulse, 0, None, pulse)\ntest_sol = librosa.util.normalize(pulse)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n\n    ftgram = stft(onset_env, n_fft=win_length, hop_length=1, center=True, window=\"hann\")\n    \n    tempo_frequencies = np.fft.rfftfreq(n=win_length, d=(sr * 60 / float(hop_length)))\n\n    ftmag = np.abs(ftgram)\n    peak_values = ftmag.max(axis=0, keepdims=True)\n    ftgram[ftmag < peak_values] = 0\n\n    ftgram[:] /= peak_values\n\n    pulse = istft(ftgram, hop_length=1, length=len(onset_env))\n\n    np.clip(pulse, 0, None, pulse)\n    return librosa.util.normalize(pulse)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.beat.plp", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute the predominant local pulse (PLP) estimation of y.", "starting_code": "import librosa\nimport numpy as np\nfrom librosa.core.spectrum import stft, istft\nfrom typing import Optional\n\n\ndef compute_plp(\n    y: np.ndarray,\n    sr: int,\n    hop_length: int,\n    win_length: int,\n    tempo_min: Optional[float],\n    tempo_max: Optional[float],\n    onset_env: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    Compute the Predominant Local Pulse (PLP) of an audio signal.\n    \n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        hop_length: The number of samples between successive frames.\n        win_length: The length (in samples) of the analysis window.\n        tempo_min: The minimum tempo (in BPM) for consideration.\n        tempo_max: The maximum tempo (in BPM) for consideration.\n        onset_env: The onset envelope of the audio signal.\n        \n    Returns:\n        The computed PLP (Predominant Local Pulse) values.\n    \"\"\"", "example_id": "293", "test": "filename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nhop_length=512\nwin_length=384\ntempo_min = None\ntempo_max = None\nonset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n\n\nsol = compute_plp(y, sr, hop_length, win_length, tempo_min, tempo_max, onset_env)\n\nftgram = stft(onset_env, n_fft=win_length, hop_length=1, center=True, window=\"hann\")\n\ntempo_frequencies = np.fft.rfftfreq(n=win_length, d=(sr * 60 / float(hop_length)))\n\nftmag = np.abs(ftgram)\npeak_values = ftmag.max(axis=0, keepdims=True)\nftgram[ftmag < peak_values] = 0\n\nftgram[:] /= peak_values\n\npulse = istft(ftgram, hop_length=1, length=len(onset_env))\n\nnp.clip(pulse, 0, None, pulse)\ntest_sol = librosa.util.normalize(pulse)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return librosa.beat.plp(onset_envelope=onset_env, sr=sr, tempo_min=tempo_min, tempo_max=tempo_max)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.beat.plp", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to return an array of time values to match the time axis from a feature matrix.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_times_like(y: np.ndarray, sr: int, hop_length: int, D: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute the times vector of a spectrogram.\n\n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        hop_length: The number of samples between successive frames.\n        D: The spectrogram.\n\n    Returns:\n        The computed times vector.\n    \"\"\"\n    ", "example_id": "294", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nD = librosa.stft(y)\nhop_length = 512 \n\nsol = compute_times_like(y, sr, hop_length, D)\n    \nif np.isscalar(D):\n    frames = np.arange(D) # type: ignore\nelse:\n    frames = np.arange(D.shape[-1]) # type: ignore\noffset = 0\nsamples = (np.asanyarray(frames) * hop_length + offset).astype(int)\n\ntest_sol = np.asanyarray(samples) / float(sr)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    if np.isscalar(D):\n        frames = np.arange(D) # type: ignore\n    else:\n        frames = np.arange(D.shape[-1]) # type: ignore\n    offset = 0\n    samples = (np.asanyarray(frames) * hop_length + offset).astype(int)\n\n    return np.asanyarray(samples) / float(sr)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.times_like", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to return an array of time values to match the time axis from a feature matrix.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_times_like(y: np.ndarray, sr: int, hop_length: int, D: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute the times vector of a spectrogram.\n\n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        hop_length: The number of samples between successive frames.\n        D: The spectrogram.\n\n    Returns:\n        The computed times vector.\n    \"\"\"\n    ", "example_id": "295", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nD = librosa.stft(y)\nhop_length = 512 \n\nsol = compute_times_like(y, sr, hop_length, D)\n    \nif np.isscalar(D):\n    frames = np.arange(D) # type: ignore\nelse:\n    frames = np.arange(D.shape[-1]) # type: ignore\noffset = 0\nsamples = (np.asanyarray(frames) * hop_length + offset).astype(int)\n\ntest_sol = np.asanyarray(samples) / float(sr)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return librosa.times_like(D, sr=sr)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.times_like", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to return an array of sample indices to match the time axis from a feature matrix.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_samples_like(y: np.ndarray, sr: int, D: np.ndarray, hop_length: int) -> np.ndarray:\n    \"\"\"\n    Compute the samples vector of a spectrogram.\n\n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        D: The spectrogram.\n    \n    Returns:\n        The computed samples vector.\n    \"\"\"\n    \n    ", "example_id": "296", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nD = librosa.stft(y)\nhop_length = 512 \n\nsol = compute_samples_like(y, sr, D, hop_length)\n\nif np.isscalar(D):\n    frames = np.arange(D) # type: ignore\nelse:\n    frames = np.arange(D.shape[-1]) # type: ignore\noffset = 0\ntest_sol = (np.asanyarray(frames) * hop_length + offset).astype(int)\n\nassert np.array_equal(test_sol, sol)", "solution": "\n    \n\n    if np.isscalar(D):\n        frames = np.arange(D) # type: ignore\n    else:\n        frames = np.arange(D.shape[-1]) # type: ignore\n    offset = 0\n    return (np.asanyarray(frames) * hop_length + offset).astype(int)\n ", "type_of_change": "new feature", "name_of_class_or_func": "librosa.samples_like", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to return an array of sample indices to match the time axis from a feature matrix.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_samples_like(y: np.ndarray, sr: int, D: np.ndarray, hop_length: int) -> np.ndarray:\n    \"\"\"\n    Compute the samples vector of a spectrogram.\n\n    Parameters:\n        y: The audio signal.\n        sr: The sampling rate of the audio signal in Hertz.\n        D: The spectrogram.\n    \n    Returns:\n        The computed samples vector.\n    \"\"\"\n    ", "example_id": "297", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nD = librosa.stft(y)\nhop_length = 512 \n\nsol = compute_samples_like(y, sr, D, hop_length)\n\nif np.isscalar(D):\n    frames = np.arange(D) # type: ignore\nelse:\n    frames = np.arange(D.shape[-1]) # type: ignore\noffset = 0\ntest_sol = (np.asanyarray(frames) * hop_length + offset).astype(int)\n\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return librosa.samples_like(D)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.samples_like", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to construct a pure tone (cosine) signal at a given frequency.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_tone(frequency: int, sr: int, length: int) -> np.ndarray:\n    \"\"\"\n    Constructs a pure tone (cosine) signal at a given frequency.\n\n    Parameters:\n        frequency: The frequency of the tone in Hz.\n        sr: The sampling rate of the signal in Hz.\n        length: The length of the signal in samples.\n\n    Returns:\n        np.ndarray: The pure tone signal.\n    \"\"\"\n    ", "example_id": "298", "test": "\nfrequency = 440\nsr = 22050\nlength = sr\n\nsol = compute_tone(frequency, sr, length)\nphi = -np.pi * 0.5\ntest_sol = np.cos(2 * np.pi * frequency * np.arange(length) / sr + phi)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    phi = -np.pi * 0.5\n    return np.cos(2 * np.pi * frequency * np.arange(length) / sr + phi)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.tone", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to construct a pure tone (cosine) signal at a given frequency.", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_tone(frequency: int, sr: int, length: int) -> np.ndarray:\n    \"\"\"\n    Constructs a pure tone (cosine) signal at a given frequency.\n\n    Parameters:\n        frequency: The frequency of the tone in Hz.\n        sr: The sampling rate of the signal in Hz.\n        length: The length of the signal in samples.\n\n    Returns:\n        np.ndarray: The pure tone signal.\n    \"\"\"\n    ", "example_id": "299", "test": "\nfrequency = 440\nsr = 22050\nlength = sr\n\nsol = compute_tone(frequency, sr, length)\ntest_sol = librosa.tone(frequency, sr=sr, length=length)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return librosa.tone(frequency, sr=sr, length=length)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.tone", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to construct a \u201cchirp\u201d or \u201csine-sweep\u201d signal. The chirp sweeps from frequency fmin to fmax (in Hz).", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_chirp(fmin: int, fmax: int, duration: int, sr: int, linear: bool) -> np.ndarray:\n    \"\"\"\n    Constructs a \u201cchirp\u201d or \u201csine-sweep\u201d signal. The chirp sweeps from frequency fmin to fmax (in Hz).\n\n    Parameters:\n        fmin: The minimum frequency of the chirp in Hz.\n        fmax: The maximum frequency of the chirp in Hz.\n        duration: The duration of the chirp in seconds.\n        sr: The sampling rate of the signal in Hz.\n\n    Returns:\n        np.ndarray: The chirp signal.\n    \"\"\"\n    ", "example_id": "300", "test": "\nimport scipy\n\nfmin = 110\nfmax = 110*64\nduration = 1\nsr = 22050\nlinear = True\n\nsol  = compute_chirp(fmin, fmax, duration, sr, linear)\nperiod = 1.0 / sr\nphi = -np.pi * 0.5\nmethod = \"linear\" if linear else \"logarithmic\"\ntest_sol = scipy.signal.chirp(\n np.arange(int(duration * sr)) / sr,\n fmin,\n duration,\n fmax,\n method=method,\n phi=phi / np.pi * 180, # scipy.signal.chirp uses degrees for phase offset\n)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    import scipy\n    period = 1.0 / sr\n    phi = -np.pi * 0.5\n\n    method = \"linear\" if linear else \"logarithmic\"\n\n    return scipy.signal.chirp(np.arange(int(duration * sr)) / sr, fmin, duration, fmax, method=method, phi=phi / np.pi * 180, )", "type_of_change": "new feature", "name_of_class_or_func": "librosa.chirp", "additional_dependencies": "pip==24.0 scikit-learn==0.21.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to construct a \u201cchirp\u201d or \u201csine-sweep\u201d signal. The chirp sweeps from frequency fmin to fmax (in Hz).", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_chirp(fmin: int, fmax: int, duration: int, sr: int, linear: bool) -> np.ndarray:\n    \"\"\"\n    Constructs a \u201cchirp\u201d or \u201csine-sweep\u201d signal. The chirp sweeps from frequency fmin to fmax (in Hz).\n\n    Parameters:\n        fmin: The minimum frequency of the chirp in Hz.\n        fmax: The maximum frequency of the chirp in Hz.\n        duration: The duration of the chirp in seconds.\n        sr: The sampling rate of the signal in Hz.\n\n    Returns:\n        np.ndarray: The chirp signal.\n    \"\"\"    \n    ", "example_id": "301", "test": "\nfmin = 110\nfmax = 110*64\nduration = 1\nsr = 22050\nlinear = True\n\nsol  = compute_chirp(fmin, fmax, duration, sr, linear)\n\ntest_sol = librosa.chirp(fmin=fmin, fmax=fmax, duration=duration, sr=sr)\nassert np.array_equal(test_sol, sol)", "solution": "\n\n    return librosa.chirp(fmin=fmin, fmax=fmax, duration=duration, sr=sr)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.chirp", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to shear a matrix by a given factor. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_shear(E: np.ndarray, factor: int, axis: int) -> np.ndarray:\n    \n", "example_id": "302", "test": "\nE = np.eye(3)\nfactor=-1\naxis=-1\n\nsol = compute_shear(E, factor, axis)\ngt = np.array([[1., 1., 1.],\n [0., 0., 0.],\n [0., 0., 0.]])\nassert np.array_equal(gt, sol)", "solution": "\n\n    E_shear = np.empty_like(E)\n    for i in range(E.shape[1]):\n        E_shear[:, i] = np.roll(E[:, i], factor * i)\n    return E_shear\n    ", "type_of_change": "new feature", "name_of_class_or_func": "librosa.util.shear", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.1", "problem": "Complete the function to shear a matrix by a given factor. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_shear(E: np.ndarray, factor: int, axis: int) -> np.ndarray:\n    \n", "example_id": "303", "test": "\nE = np.eye(3)\nfactor=-1\naxis=-1\n\nsol = compute_shear(E, factor, axis)\ngt = np.array([[1., 1., 1.],\n [0., 0., 0.],\n [0., 0., 0.]])\nassert np.array_equal(gt, sol)", "solution": "\n\n    return librosa.util.shear(E, factor=factor, axis=axis)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.util.shear", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to locate the local minimas of an array. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_localmin(x: np.ndarray, axis: int) -> np.ndarray:\n    ", "example_id": "304", "test": "\naxis=0\nx = np.array([[1,0,1], [2, -1, 0], [2, 1, 3]])\n\nsol = compute_localmin(x, axis)\ngt = np.array([[False, False, False],\n [False, True, True],\n [False, False, False]])\n\nassert np.array_equal(gt, sol)", "solution": "\n\n    return librosa.util.localmax(-x, axis=axis)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.util.localmin", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.8.0", "problem": "Complete the function to locate the local minimas of an array. ", "starting_code": "import librosa\nimport numpy as np\n\ndef compute_localmin(x: np.ndarray, axis: int) -> np.ndarray:\n    ", "example_id": "305", "test": "\naxis=0\nx = np.array([[1,0,1], [2, -1, 0], [2, 1, 3]])\n\nsol = compute_localmin(x, axis)\n\ngt = np.array([[False, False, False],\n [False, True, True],\n [False, False, False]])\n\nassert np.array_equal(gt, sol)", "solution": "\n\n    return librosa.util.localmin(x, axis=axis)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.util.localmin", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to calculate the fundamental frequency (F0) estimation using the YIN algorithm.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Optional\n\ndef compute_yin(sr: int, fmin: int, fmax: int, duration: float, period: float, phi: float, method: str, y: np.ndarray, frame_length: int, center: bool, pad_mode: str, win_length: Optional[int], hop_length: Optional[int], trough_threshold: float) -> np.ndarray:\n    \"\"\"\n    Calculates the fundamental frequency (F0) estimation using the YIN algorithm.\n\n    Parameters:\n        sr: The sampling rate of the audio signal in Hertz.\n        fmin: The minimum frequency to consider in Hz.\n        fmax: The maximum frequency to consider in Hz.\n        duration: The duration of the audio signal in seconds.\n        period: The period of the fundamental frequency in seconds.\n        phi: The phase of the fundamental frequency in radians.\n        method: Interpolation method.\n        y: The audio signal.\n        frame_length: The length of the frame in samples.\n        center: If True, the signal y is padded so that frame t is centered at y[t * hop_length].\n        pad_mode: Padding mode.\n        win_length: Window length.\n        hop_length: Hop length.\n        trough_threshold: Absolute threshold for peak estimation.\n\n    Returns:\n        The estimated fundamental frequency in Hz.\n    \"\"\"\n    \n    \n\n\n    ", "example_id": "306", "test": "sr=22050\nfmin = 440\nfmax = 880\nduration = 5.0\nperiod = 1.0 / sr\nphi = -np.pi * 0.5\nmethod = \"linear\" \ny = scipy.signal.chirp(\n np.arange(int(duration * sr)) / sr,\n fmin,\n duration,\n fmax,\n method=method,\n phi=phi / np.pi * 180, # scipy.signal.chirp uses degrees for phase offset\n)\nframe_length = 2048\ncenter = True\npad_mode = 'reflect'\nwin_length = None\nhop_length = None\ntrough_threshold = 0.1\n\nsol = compute_yin(sr, fmin, fmax, duration, period, phi, method, y, frame_length, center, pad_mode, win_length, hop_length, trough_threshold)\nif win_length is None:\n win_length = frame_length // 2\n\nif hop_length is None:\n hop_length = frame_length // 4\n\nif center:\n y = np.pad(y, frame_length // 2, mode=pad_mode)\n\ny_frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n\nmin_period = max(int(np.floor(sr / fmax)), 1)\nmax_period = min(int(np.ceil(sr / fmin)), frame_length - win_length - 1)\n\na = np.fft.rfft(y_frames, frame_length, axis=0)\nb = np.fft.rfft(y_frames[win_length::-1, :], frame_length, axis=0)\nacf_frames = np.fft.irfft(a * b, frame_length, axis=0)[win_length:]\nacf_frames[np.abs(acf_frames) < 1e-6] = 0\n\nenergy_frames = np.cumsum(y_frames ** 2, axis=0)\nenergy_frames = energy_frames[win_length:, :] - energy_frames[:-win_length, :]\nenergy_frames[np.abs(energy_frames) < 1e-6] = 0\n\nyin_frames = energy_frames[0, :] + energy_frames - 2 * acf_frames\n\nyin_numerator = yin_frames[min_period : max_period + 1, :]\ntau_range = np.arange(1, max_period + 1)[:, None]\ncumulative_mean = np.cumsum(yin_frames[1 : max_period + 1, :], axis=0) / tau_range\nyin_denominator = cumulative_mean[min_period - 1 : max_period, :]\nyin_frames = yin_numerator / (yin_denominator + librosa.util.tiny(yin_denominator))\n\nparabolic_shifts = np.zeros_like(yin_frames)\nparabola_a = (yin_frames[:-2, :] + yin_frames[2:, :] - 2 * yin_frames[1:-1, :]) / 2\nparabola_b = (yin_frames[2:, :] - yin_frames[:-2, :]) / 2\nparabolic_shifts[1:-1, :] = -parabola_b / (2 * parabola_a + librosa.util.tiny(parabola_a))\nparabolic_shifts[np.abs(parabolic_shifts) > 1] = 0\n\nis_trough = librosa.util.localmax(-yin_frames, axis=0)\nis_trough[0, :] = yin_frames[0, :] < yin_frames[1, :]\n\nis_threshold_trough = np.logical_and(is_trough, yin_frames < trough_threshold)\n\nglobal_min = np.argmin(yin_frames, axis=0)\nyin_period = np.argmax(is_threshold_trough, axis=0)\nno_trough_below_threshold = np.all(~is_threshold_trough, axis=0)\nyin_period[no_trough_below_threshold] = global_min[no_trough_below_threshold]\n\nyin_period = (\n min_period\n + yin_period\n + parabolic_shifts[yin_period, range(yin_frames.shape[1])]\n)\n\ntest_sol = sr / yin_period\nassert np.allclose(test_sol, sol)", "solution": "\n    # Set the default window length if it is not already specified.\n    if win_length is None:\n        win_length = frame_length // 2\n\n\n    # Set the default hop if it is not already specified.\n    if hop_length is None:\n        hop_length = frame_length // 4\n\n    # Pad the time series so that frames are centered\n    if center:\n        y = np.pad(y, frame_length // 2, mode=pad_mode)\n\n    # Frame audio.\n    y_frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n\n    # Calculate minimum and maximum periods\n    min_period = max(int(np.floor(sr / fmax)), 1)\n    max_period = min(int(np.ceil(sr / fmin)), frame_length - win_length - 1)\n\n    # Calculate cumulative mean normalized difference function.\n    # Autocorrelation.\n    a = np.fft.rfft(y_frames, frame_length, axis=0)\n    b = np.fft.rfft(y_frames[win_length::-1, :], frame_length, axis=0)\n    acf_frames = np.fft.irfft(a * b, frame_length, axis=0)[win_length:]\n    acf_frames[np.abs(acf_frames) < 1e-6] = 0\n\n    # Energy terms.\n    energy_frames = np.cumsum(y_frames ** 2, axis=0)\n    energy_frames = energy_frames[win_length:, :] - energy_frames[:-win_length, :]\n    energy_frames[np.abs(energy_frames) < 1e-6] = 0\n\n    # Difference function.\n    yin_frames = energy_frames[0, :] + energy_frames - 2 * acf_frames\n\n    # Cumulative mean normalized difference function.\n    yin_numerator = yin_frames[min_period : max_period + 1, :]\n    tau_range = np.arange(1, max_period + 1)[:, None]\n    cumulative_mean = np.cumsum(yin_frames[1 : max_period + 1, :], axis=0) / tau_range\n    yin_denominator = cumulative_mean[min_period - 1 : max_period, :]\n    yin_frames = yin_numerator / (yin_denominator + librosa.util.tiny(yin_denominator))\n\n    parabolic_shifts = np.zeros_like(yin_frames)\n    parabola_a = (yin_frames[:-2, :] + yin_frames[2:, :] - 2 * yin_frames[1:-1, :]) / 2\n    parabola_b = (yin_frames[2:, :] - yin_frames[:-2, :]) / 2\n    parabolic_shifts[1:-1, :] = -parabola_b / (2 * parabola_a + librosa.util.tiny(parabola_a))\n    parabolic_shifts[np.abs(parabolic_shifts) > 1] = 0\n\n    # Find local minima.\n    is_trough = librosa.util.localmax(-yin_frames, axis=0)\n    is_trough[0, :] = yin_frames[0, :] < yin_frames[1, :]\n\n    # Find minima below peak threshold.\n    is_threshold_trough = np.logical_and(is_trough, yin_frames < trough_threshold)\n\n    # Absolute threshold.\n    # \"The solution we propose is to set an absolute threshold and choose the\n    # smallest value of tau that gives a minimum of d' deeper than\n    # this threshold. If none is found, the global minimum is chosen instead.\"\n    global_min = np.argmin(yin_frames, axis=0)\n    yin_period = np.argmax(is_threshold_trough, axis=0)\n    no_trough_below_threshold = np.all(~is_threshold_trough, axis=0)\n    yin_period[no_trough_below_threshold] = global_min[no_trough_below_threshold]\n\n    # Refine peak by parabolic interpolation.\n    yin_period = (\n     min_period\n     + yin_period\n     + parabolic_shifts[yin_period, range(yin_frames.shape[1])]\n    )\n\n    # Convert period to fundamental frequency.\n    return sr / yin_period", "type_of_change": "new feature", "name_of_class_or_func": "librosa.yin", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.12 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.8.0", "problem": "Complete the function to calculate the fundamental frequency (F0) estimation using the YIN algorithm.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Optional\n\ndef compute_yin(sr: int, fmin: int, fmax: int, duration: float, period: float, phi: float, method: str, y: np.ndarray, frame_length: int, center: bool, pad_mode: str, win_length: Optional[int], hop_length: Optional[int], trough_threshold: float) -> np.ndarray:\n    \"\"\"\n    Calculates the fundamental frequency (F0) estimation using the YIN algorithm.\n\n    Parameters:\n        sr: The sampling rate of the audio signal in Hertz.\n        fmin: The minimum frequency to consider in Hz.\n        fmax: The maximum frequency to consider in Hz.\n        duration: The duration of the audio signal in seconds.\n        period: The period of the fundamental frequency in seconds.\n        phi: The phase of the fundamental frequency in radians.\n        method: Interpolation method.\n        y: The audio signal.\n        frame_length: The length of the frame in samples.\n        center: If True, the signal y is padded so that frame t is centered at y[t * hop_length].\n        pad_mode: Padding mode.\n        win_length: Window length.\n        hop_length: Hop length.\n        trough_threshold: Absolute threshold for peak estimation.\n\n    Returns:\n        The estimated fundamental frequency in Hz.\n    \"\"\"\n", "example_id": "307", "test": "sr=22050\nfmin = 440\nfmax = 880\nduration = 5.0\nperiod = 1.0 / sr\nphi = -np.pi * 0.5\nmethod = \"linear\" \ny = scipy.signal.chirp(\n np.arange(int(duration * sr)) / sr,\n fmin,\n duration,\n fmax,\n method=method,\n phi=phi / np.pi * 180, # scipy.signal.chirp uses degrees for phase offset\n)\nframe_length = 2048\ncenter = True\npad_mode = 'reflect'\nwin_length = None\nhop_length = None\ntrough_threshold = 0.1\n\nsol = compute_yin(sr, fmin, fmax, duration, period, phi, method, y, frame_length, center, pad_mode, win_length, hop_length, trough_threshold)\nif win_length is None:\n win_length = frame_length // 2\n\nif hop_length is None:\n hop_length = frame_length // 4\n\nif center:\n y = np.pad(y, frame_length // 2, mode=pad_mode)\n\ny_frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n\nmin_period = max(int(np.floor(sr / fmax)), 1)\nmax_period = min(int(np.ceil(sr / fmin)), frame_length - win_length - 1)\n\na = np.fft.rfft(y_frames, frame_length, axis=0)\nb = np.fft.rfft(y_frames[win_length::-1, :], frame_length, axis=0)\nacf_frames = np.fft.irfft(a * b, frame_length, axis=0)[win_length:]\nacf_frames[np.abs(acf_frames) < 1e-6] = 0\n\nenergy_frames = np.cumsum(y_frames ** 2, axis=0)\nenergy_frames = energy_frames[win_length:, :] - energy_frames[:-win_length, :]\nenergy_frames[np.abs(energy_frames) < 1e-6] = 0\n\nyin_frames = energy_frames[0, :] + energy_frames - 2 * acf_frames\n\nyin_numerator = yin_frames[min_period : max_period + 1, :]\ntau_range = np.arange(1, max_period + 1)[:, None]\ncumulative_mean = np.cumsum(yin_frames[1 : max_period + 1, :], axis=0) / tau_range\nyin_denominator = cumulative_mean[min_period - 1 : max_period, :]\nyin_frames = yin_numerator / (yin_denominator + librosa.util.tiny(yin_denominator))\n\nparabolic_shifts = np.zeros_like(yin_frames)\nparabola_a = (yin_frames[:-2, :] + yin_frames[2:, :] - 2 * yin_frames[1:-1, :]) / 2\nparabola_b = (yin_frames[2:, :] - yin_frames[:-2, :]) / 2\nparabolic_shifts[1:-1, :] = -parabola_b / (2 * parabola_a + librosa.util.tiny(parabola_a))\nparabolic_shifts[np.abs(parabolic_shifts) > 1] = 0\n\nis_trough = librosa.util.localmax(-yin_frames, axis=0)\nis_trough[0, :] = yin_frames[0, :] < yin_frames[1, :]\n\nis_threshold_trough = np.logical_and(is_trough, yin_frames < trough_threshold)\n\nglobal_min = np.argmin(yin_frames, axis=0)\nyin_period = np.argmax(is_threshold_trough, axis=0)\nno_trough_below_threshold = np.all(~is_threshold_trough, axis=0)\nyin_period[no_trough_below_threshold] = global_min[no_trough_below_threshold]\n\nyin_period = (\n min_period\n + yin_period\n + parabolic_shifts[yin_period, range(yin_frames.shape[1])]\n)\n\ntest_sol = sr / yin_period\nassert np.allclose(test_sol, sol)", "solution": "\n\n    return librosa.yin(y, fmin=fmin, fmax=fmax, sr=sr)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.yin", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to calculate the fundamental frequency estimation using probabilistic YIN.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Union, Optional, Tuple\n\nDTypeLike = Union[np.dtype, type]\n\ndef compute_pyin(freq: int, sr: int, y: np.ndarray, fmin: int, fmax: int, frame_length: int, center: bool, pad_mode: str, win_length: Optional[int], hop_length: Optional[int], n_thresholds: int, beta_parameters: Tuple[int], boltzmann_parameter: int, resolution: float, max_transition_rate: float, switch_prob: float, no_trough_prob: float, fill_na: DTypeLike) -> np.ndarray:\n    \"\"\"\n    Calculates the fundamental frequency estimation using probabilistic YIN.\n\n    Parameters:\n        freq: The frequency of the fundamental frequency in Hz.\n        sr: The sampling rate of the audio signal in Hertz.\n        y: The audio signal.\n        fmin: The minimum frequency to consider in Hz.\n        fmax: The maximum frequency to consider in Hz.\n        frame_length: The length of the frame in samples.\n        center: If True, the signal y is padded so that frame t is centered at y[t * hop_length].\n        pad_mode: Padding mode.\n        win_length: Window length.\n        hop_length: Hop length.\n        n_thresholds: Number of thresholds.\n        beta_parameters: Beta parameters.\n        boltzmann_parameter: Boltzmann parameter.\n        resolution: Resolution.\n        max_transition_rate: Maximum transition rate.\n        switch_prob: Switch probability.\n        no_trough_prob: No trough probability.\n        fill_na: Fill NA value.\n\n    Returns:\n        Time series of fundamental frequencies in Hertz.\n    \"\"\"\n    ", "example_id": "308", "test": "\nfreq=110\nsr=22050\ny = librosa.tone(freq, duration=1.0)\nfmin = 110\nfmax = 880\nframe_length = 2048\ncenter = False\npad_mode = 'reflect'\nwin_length = None\nhop_length = None\n#trough_threshold = 0.1\n\nn_thresholds=100\nbeta_parameters=(2, 18)\nboltzmann_parameter=2\nresolution=0.1\nmax_transition_rate=35.92\nswitch_prob=0.01\nno_trough_prob=0.01\nfill_na=np.nan\n\nsol = compute_pyin(freq, sr, y, fmin, fmax, frame_length, center, pad_mode, win_length, hop_length, n_thresholds, beta_parameters, boltzmann_parameter, resolution, max_transition_rate, switch_prob, no_trough_prob, fill_na)\n\nif win_length is None:\n    win_length = frame_length // 2\n\nif hop_length is None:\n    hop_length = frame_length // 4\n\nif center:\n    y = np.pad(y, frame_length // 2, mode=pad_mode)\n\ny_frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n\nmin_period = max(int(np.floor(sr / fmax)), 1)\nmax_period = min(int(np.ceil(sr / fmin)), frame_length - win_length - 1)\n\na = np.fft.rfft(y_frames, frame_length, axis=0)\nb = np.fft.rfft(y_frames[win_length::-1, :], frame_length, axis=0)\nacf_frames = np.fft.irfft(a * b, frame_length, axis=0)[win_length:]\nacf_frames[np.abs(acf_frames) < 1e-6] = 0\n\nenergy_frames = np.cumsum(y_frames ** 2, axis=0)\nenergy_frames = energy_frames[win_length:, :] - energy_frames[:-win_length, :]\nenergy_frames[np.abs(energy_frames) < 1e-6] = 0\n\nyin_frames = energy_frames[0, :] + energy_frames - 2 * acf_frames\n\nyin_numerator = yin_frames[min_period : max_period + 1, :]\ntau_range = np.arange(1, max_period + 1)[:, None]\ncumulative_mean = np.cumsum(yin_frames[1 : max_period + 1, :], axis=0) / tau_range\nyin_denominator = cumulative_mean[min_period - 1 : max_period, :]\nyin_frames = yin_numerator / (yin_denominator + librosa.util.tiny(yin_denominator))\n\nparabolic_shifts = np.zeros_like(yin_frames)\nparabola_a = (yin_frames[:-2, :] + yin_frames[2:, :] - 2 * yin_frames[1:-1, :]) / 2\nparabola_b = (yin_frames[2:, :] - yin_frames[:-2, :]) / 2\nparabolic_shifts[1:-1, :] = -parabola_b / (2 * parabola_a + librosa.util.tiny(parabola_a))\nparabolic_shifts[np.abs(parabolic_shifts) > 1] = 0\n\nthresholds = np.linspace(0, 1, n_thresholds + 1)\nbeta_cdf = scipy.stats.beta.cdf(thresholds, beta_parameters[0], beta_parameters[1])\nbeta_probs = np.diff(beta_cdf)\n\nyin_probs = np.zeros_like(yin_frames)\nfor i, yin_frame in enumerate(yin_frames.T):\n    is_trough = librosa.util.localmax(-yin_frame, axis=0)\n    is_trough[0] = yin_frame[0] < yin_frame[1]\n    (trough_index,) = np.nonzero(is_trough)\n\n    if len(trough_index) == 0:\n        continue\n    trough_heights = yin_frame[trough_index]\n    trough_thresholds = trough_heights[:, None] < thresholds[None, 1:]\n\n    trough_positions = np.cumsum(trough_thresholds, axis=0) - 1\n    n_troughs = np.count_nonzero(trough_thresholds, axis=0)\n    trough_prior = scipy.stats.boltzmann.pmf(\n        trough_positions, boltzmann_parameter, n_troughs\n    )\n    trough_prior[~trough_thresholds] = 0\n\n    probs = np.sum(trough_prior * beta_probs, axis=1)\n    global_min = np.argmin(trough_heights)\n    n_thresholds_below_min = np.count_nonzero(~trough_thresholds[global_min, :])\n    probs[global_min] += no_trough_prob * np.sum(\n        beta_probs[:n_thresholds_below_min]\n    )\n\n    yin_probs[trough_index, i] = probs\n\nyin_period, frame_index = np.nonzero(yin_probs)\n\nperiod_candidates = min_period + yin_period\nperiod_candidates = period_candidates + parabolic_shifts[yin_period, frame_index]\nf0_candidates = sr / period_candidates\n\nn_bins_per_semitone = int(np.ceil(1.0 / resolution))\nn_pitch_bins = int(np.floor(12 * n_bins_per_semitone * np.log2(fmax / fmin))) + 1\n\n\nmax_semitones_per_frame = round(max_transition_rate * 12 * hop_length / sr)\ntransition_width = max_semitones_per_frame * n_bins_per_semitone + 1\n\ntransition = librosa.sequence.transition_local(\n    n_pitch_bins, transition_width, window=\"triangle\", wrap=False\n)\ntransition = np.block(\n    [\n        [(1 - switch_prob) * transition, switch_prob * transition],\n        [switch_prob * transition, (1 - switch_prob) * transition],\n    ]\n)\n\nbin_index = 12 * n_bins_per_semitone * np.log2(f0_candidates / fmin)\nbin_index = np.clip(np.round(bin_index), 0, n_pitch_bins).astype(int)\n\nobservation_probs = np.zeros((2 * n_pitch_bins, yin_frames.shape[1]))\nobservation_probs[bin_index, frame_index] = yin_probs[yin_period, frame_index]\nvoiced_prob = np.clip(np.sum(observation_probs[:n_pitch_bins, :], axis=0), 0, 1)\nobservation_probs[n_pitch_bins:, :] = (1 - voiced_prob[None, :]) / n_pitch_bins\n\np_init = np.zeros(2 * n_pitch_bins)\np_init[n_pitch_bins:] = 1 / n_pitch_bins\n\nstates = librosa.sequence.viterbi(observation_probs, transition, p_init=p_init)\n\nfreqs = fmin * 2 ** (np.arange(n_pitch_bins) / (12 * n_bins_per_semitone))\nf0 = freqs[states % n_pitch_bins]\nvoiced_flag = states < n_pitch_bins\nif fill_na is not None:\n    f0[~voiced_flag] = fill_na\ntest_sol = f0\nassert np.allclose(test_sol, sol)\nassert np.allclose(np.log2(sol), np.log2(freq), rtol=0, atol=1e-2)", "solution": "\n\n\n    if win_length is None:\n        win_length = frame_length // 2\n    \n    if hop_length is None:\n        hop_length = frame_length // 4\n    \n    if center:\n        y = np.pad(y, frame_length // 2, mode=pad_mode)\n    \n    y_frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n    \n    min_period = max(int(np.floor(sr / fmax)), 1)\n    max_period = min(int(np.ceil(sr / fmin)), frame_length - win_length - 1)\n    \n    a = np.fft.rfft(y_frames, frame_length, axis=0)\n    b = np.fft.rfft(y_frames[win_length::-1, :], frame_length, axis=0)\n    acf_frames = np.fft.irfft(a * b, frame_length, axis=0)[win_length:]\n    acf_frames[np.abs(acf_frames) < 1e-6] = 0\n    \n    energy_frames = np.cumsum(y_frames ** 2, axis=0)\n    energy_frames = energy_frames[win_length:, :] - energy_frames[:-win_length, :]\n    energy_frames[np.abs(energy_frames) < 1e-6] = 0\n    \n    yin_frames = energy_frames[0, :] + energy_frames - 2 * acf_frames\n    \n    yin_numerator = yin_frames[min_period : max_period + 1, :]\n    tau_range = np.arange(1, max_period + 1)[:, None]\n    cumulative_mean = np.cumsum(yin_frames[1 : max_period + 1, :], axis=0) / tau_range\n    yin_denominator = cumulative_mean[min_period - 1 : max_period, :]\n    yin_frames = yin_numerator / (yin_denominator + librosa.util.tiny(yin_denominator))\n    \n    parabolic_shifts = np.zeros_like(yin_frames)\n    parabola_a = (yin_frames[:-2, :] + yin_frames[2:, :] - 2 * yin_frames[1:-1, :]) / 2\n    parabola_b = (yin_frames[2:, :] - yin_frames[:-2, :]) / 2\n    parabolic_shifts[1:-1, :] = -parabola_b / (2 * parabola_a + librosa.util.tiny(parabola_a))\n    parabolic_shifts[np.abs(parabolic_shifts) > 1] = 0\n    \n    thresholds = np.linspace(0, 1, n_thresholds + 1)\n    beta_cdf = scipy.stats.beta.cdf(thresholds, beta_parameters[0], beta_parameters[1])\n    beta_probs = np.diff(beta_cdf)\n    \n    yin_probs = np.zeros_like(yin_frames)\n    for i, yin_frame in enumerate(yin_frames.T):\n        is_trough = librosa.util.localmax(-yin_frame, axis=0)\n        is_trough[0] = yin_frame[0] < yin_frame[1]\n        (trough_index,) = np.nonzero(is_trough)\n    \n        if len(trough_index) == 0:\n            continue\n        \n        trough_heights = yin_frame[trough_index]\n        trough_thresholds = trough_heights[:, None] < thresholds[None, 1:]\n    \n        trough_positions = np.cumsum(trough_thresholds, axis=0) - 1\n        n_troughs = np.count_nonzero(trough_thresholds, axis=0)\n        trough_prior = scipy.stats.boltzmann.pmf(\n            trough_positions, boltzmann_parameter, n_troughs\n        )\n        trough_prior[~trough_thresholds] = 0\n    \n        probs = np.sum(trough_prior * beta_probs, axis=1)\n        global_min = np.argmin(trough_heights)\n        n_thresholds_below_min = np.count_nonzero(~trough_thresholds[global_min, :])\n        probs[global_min] += no_trough_prob * np.sum(\n            beta_probs[:n_thresholds_below_min]\n        )\n    \n        yin_probs[trough_index, i] = probs\n    \n    yin_period, frame_index = np.nonzero(yin_probs)\n    \n\n    period_candidates = min_period + yin_period\n    period_candidates = period_candidates + parabolic_shifts[yin_period, frame_index]\n    f0_candidates = sr / period_candidates\n    \n    n_bins_per_semitone = int(np.ceil(1.0 / resolution))\n    n_pitch_bins = int(np.floor(12 * n_bins_per_semitone * np.log2(fmax / fmin))) + 1\n    \n\n    max_semitones_per_frame = round(max_transition_rate * 12 * hop_length / sr)\n    transition_width = max_semitones_per_frame * n_bins_per_semitone + 1\n\n    transition = librosa.sequence.transition_local(\n        n_pitch_bins, transition_width, window=\"triangle\", wrap=False\n    )\n\n    transition = np.block(\n        [\n            [(1 - switch_prob) * transition, switch_prob * transition],\n            [switch_prob * transition, (1 - switch_prob) * transition],\n        ]\n    )\n    \n    bin_index = 12 * n_bins_per_semitone * np.log2(f0_candidates / fmin)\n    bin_index = np.clip(np.round(bin_index), 0, n_pitch_bins).astype(int)\n    \n    observation_probs = np.zeros((2 * n_pitch_bins, yin_frames.shape[1]))\n    observation_probs[bin_index, frame_index] = yin_probs[yin_period, frame_index]\n    voiced_prob = np.clip(np.sum(observation_probs[:n_pitch_bins, :], axis=0), 0, 1)\n    observation_probs[n_pitch_bins:, :] = (1 - voiced_prob[None, :]) / n_pitch_bins\n    \n    p_init = np.zeros(2 * n_pitch_bins)\n    p_init[n_pitch_bins:] = 1 / n_pitch_bins\n    \n    states = librosa.sequence.viterbi(observation_probs, transition, p_init=p_init)\n    \n    freqs = fmin * 2 ** (np.arange(n_pitch_bins) / (12 * n_bins_per_semitone))\n    f0 = freqs[states % n_pitch_bins]\n    voiced_flag = states < n_pitch_bins\n    if fill_na is not None:\n        f0[~voiced_flag] = fill_na\n    \n    return f0", "type_of_change": "new feature", "name_of_class_or_func": "librosa.pyin", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.8.0", "problem": "Complete the function to calculate the fundamental frequency estimation using probabilistic YIN.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Union, Optional, Tuple\n\nDTypeLike = Union[np.dtype, type]\n\ndef compute_pyin(freq: int, sr: int, y: int, fmin: int, fmax: int, frame_length: int, center: bool, pad_mode: str, win_length: Optional[int], hop_length: Optional[int], n_thresholds: int, beta_parameters: Tuple[int], boltzmann_parameter: int, resolution: float, max_transition_rate: float, switch_prob: float, no_trough_prob: float, fill_na: DTypeLike) -> np.ndarray:\n    \"\"\"\n    Calculates the fundamental frequency estimation using probabilistic YIN.\n\n    Parameters:\n        freq: The frequency of the fundamental frequency in Hz.\n        sr: The sampling rate of the audio signal in Hertz.\n        y: The audio signal.\n        fmin: The minimum frequency to consider in Hz.\n        fmax: The maximum frequency to consider in Hz.\n        frame_length: The length of the frame in samples.\n        center: If True, the signal y is padded so that frame t is centered at y[t * hop_length].\n        pad_mode: Padding mode.\n        win_length: Window length.\n        hop_length: Hop length.\n        n_thresholds: Number of thresholds.\n        beta_parameters: Beta parameters.\n        boltzmann_parameter: Boltzmann parameter.\n        resolution: Resolution.\n        max_transition_rate: Maximum transition rate.\n        switch_prob: Switch probability.\n        no_trough_prob: No trough probability.\n        fill_na: Fill NA value.\n\n    Returns:\n        Time series of fundamental frequencies in Hertz.\n    \"\"\"    ", "example_id": "309", "test": "\nfreq=110\nsr=22050\ny = librosa.tone(freq, duration=1.0)\nfmin = 110\nfmax = 880\nframe_length = 2048\ncenter = False\npad_mode = 'reflect'\nwin_length = None\nhop_length = None\n#trough_threshold = 0.1\n\nn_thresholds=100\nbeta_parameters=(2, 18)\nboltzmann_parameter=2\nresolution=0.1\nmax_transition_rate=35.92\nswitch_prob=0.01\nno_trough_prob=0.01\nfill_na=np.nan\n\nsol = compute_pyin(freq, sr, y, fmin, fmax, frame_length, center, pad_mode, win_length, hop_length, n_thresholds, beta_parameters, boltzmann_parameter, resolution, max_transition_rate, switch_prob, no_trough_prob, fill_na)\n\nif win_length is None:\n    win_length = frame_length // 2\n\nif hop_length is None:\n    hop_length = frame_length // 4\n\nif center:\n    y = np.pad(y, frame_length // 2, mode=pad_mode)\n\ny_frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)\n\nmin_period = max(int(np.floor(sr / fmax)), 1)\nmax_period = min(int(np.ceil(sr / fmin)), frame_length - win_length - 1)\n\na = np.fft.rfft(y_frames, frame_length, axis=0)\nb = np.fft.rfft(y_frames[win_length::-1, :], frame_length, axis=0)\nacf_frames = np.fft.irfft(a * b, frame_length, axis=0)[win_length:]\nacf_frames[np.abs(acf_frames) < 1e-6] = 0\n\nenergy_frames = np.cumsum(y_frames ** 2, axis=0)\nenergy_frames = energy_frames[win_length:, :] - energy_frames[:-win_length, :]\nenergy_frames[np.abs(energy_frames) < 1e-6] = 0\n\nyin_frames = energy_frames[0, :] + energy_frames - 2 * acf_frames\n\nyin_numerator = yin_frames[min_period : max_period + 1, :]\ntau_range = np.arange(1, max_period + 1)[:, None]\ncumulative_mean = np.cumsum(yin_frames[1 : max_period + 1, :], axis=0) / tau_range\nyin_denominator = cumulative_mean[min_period - 1 : max_period, :]\nyin_frames = yin_numerator / (yin_denominator + librosa.util.tiny(yin_denominator))\n\nparabolic_shifts = np.zeros_like(yin_frames)\nparabola_a = (yin_frames[:-2, :] + yin_frames[2:, :] - 2 * yin_frames[1:-1, :]) / 2\nparabola_b = (yin_frames[2:, :] - yin_frames[:-2, :]) / 2\nparabolic_shifts[1:-1, :] = -parabola_b / (2 * parabola_a + librosa.util.tiny(parabola_a))\nparabolic_shifts[np.abs(parabolic_shifts) > 1] = 0\n\nthresholds = np.linspace(0, 1, n_thresholds + 1)\nbeta_cdf = scipy.stats.beta.cdf(thresholds, beta_parameters[0], beta_parameters[1])\nbeta_probs = np.diff(beta_cdf)\n\nyin_probs = np.zeros_like(yin_frames)\nfor i, yin_frame in enumerate(yin_frames.T):\n    is_trough = librosa.util.localmax(-yin_frame, axis=0)\n    is_trough[0] = yin_frame[0] < yin_frame[1]\n    (trough_index,) = np.nonzero(is_trough)\n\n    if len(trough_index) == 0:\n        continue\n    trough_heights = yin_frame[trough_index]\n    trough_thresholds = trough_heights[:, None] < thresholds[None, 1:]\n\n    trough_positions = np.cumsum(trough_thresholds, axis=0) - 1\n    n_troughs = np.count_nonzero(trough_thresholds, axis=0)\n    trough_prior = scipy.stats.boltzmann.pmf(\n        trough_positions, boltzmann_parameter, n_troughs\n    )\n    trough_prior[~trough_thresholds] = 0\n\n    probs = np.sum(trough_prior * beta_probs, axis=1)\n    global_min = np.argmin(trough_heights)\n    n_thresholds_below_min = np.count_nonzero(~trough_thresholds[global_min, :])\n    probs[global_min] += no_trough_prob * np.sum(\n        beta_probs[:n_thresholds_below_min]\n    )\n\n    yin_probs[trough_index, i] = probs\n\nyin_period, frame_index = np.nonzero(yin_probs)\n\nperiod_candidates = min_period + yin_period\nperiod_candidates = period_candidates + parabolic_shifts[yin_period, frame_index]\nf0_candidates = sr / period_candidates\n\nn_bins_per_semitone = int(np.ceil(1.0 / resolution))\nn_pitch_bins = int(np.floor(12 * n_bins_per_semitone * np.log2(fmax / fmin))) + 1\n\n\nmax_semitones_per_frame = round(max_transition_rate * 12 * hop_length / sr)\ntransition_width = max_semitones_per_frame * n_bins_per_semitone + 1\n\ntransition = librosa.sequence.transition_local(\n    n_pitch_bins, transition_width, window=\"triangle\", wrap=False\n)\ntransition = np.block(\n    [\n        [(1 - switch_prob) * transition, switch_prob * transition],\n        [switch_prob * transition, (1 - switch_prob) * transition],\n    ]\n)\n\nbin_index = 12 * n_bins_per_semitone * np.log2(f0_candidates / fmin)\nbin_index = np.clip(np.round(bin_index), 0, n_pitch_bins).astype(int)\n\nobservation_probs = np.zeros((2 * n_pitch_bins, yin_frames.shape[1]))\nobservation_probs[bin_index, frame_index] = yin_probs[yin_period, frame_index]\nvoiced_prob = np.clip(np.sum(observation_probs[:n_pitch_bins, :], axis=0), 0, 1)\nobservation_probs[n_pitch_bins:, :] = (1 - voiced_prob[None, :]) / n_pitch_bins\n\np_init = np.zeros(2 * n_pitch_bins)\np_init[n_pitch_bins:] = 1 / n_pitch_bins\n\nstates = librosa.sequence.viterbi(observation_probs, transition, p_init=p_init)\n\nfreqs = fmin * 2 ** (np.arange(n_pitch_bins) / (12 * n_bins_per_semitone))\nf0 = freqs[states % n_pitch_bins]\nvoiced_flag = states < n_pitch_bins\nif fill_na is not None:\n    f0[~voiced_flag] = fill_na\ntest_sol = f0\nassert np.allclose(test_sol, sol)\nassert np.allclose(np.log2(sol), np.log2(freq), rtol=0, atol=1e-2)", "solution": "\n\n    return librosa.pyin(y, fmin=fmin, fmax=fmax, center=center)[0]", "type_of_change": "new feature", "name_of_class_or_func": "librosa.pyin", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute the variable-Q transform of an audio signal.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Union\n\nDTypeLike = Union[np.dtype, type]\n\n\ndef compute_vqt(y: np.ndarray, sr: int, hop_length: int, fmin: int, n_bins: int, gamma: int, bins_per_octave: int, tuning: float, filter_scale: int, norm: 1, sparsity: float, window: str, scale: bool, pad_mode: str, res_type: str, dtype: DTypeLike) -> np.ndarray:\n    ", "example_id": "310", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nhop_length=512\nfmin=None\nn_bins=84\ngamma=None\nbins_per_octave=12\ntuning=0.0\nfilter_scale=1\nnorm=1\nsparsity=0.01\nwindow=\"hann\"\nscale=True\npad_mode=\"reflect\"\nres_type=None\ndtype=None\n\nsol = compute_vqt(y, sr, hop_length, fmin, n_bins, gamma, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\n\ndef dtype_r2c(d, default=np.complex64):\n    mapping = {\n        np.dtype(np.float32): np.complex64,\n        np.dtype(np.float64): np.complex128,\n        np.dtype(np.float): np.complex,\n    }\n\n    dt = np.dtype(d)\n    if dt.kind == \"c\":\n        return dt\n\n    return np.dtype(mapping.get(dt, default))\n\nn_octaves = int(np.ceil(float(n_bins) / bins_per_octave))\nn_filters = min(bins_per_octave, n_bins)\n\nlen_orig = len(y)\n\nalpha = 2.0 ** (1.0 / bins_per_octave) - 1\n\nif fmin is None:\n    fmin = librosa.note_to_hz(\"C1\")\n\nif tuning is None:\n    tuning = librosa.pitch.estimate_tuning(y=y, sr=sr, bins_per_octave=bins_per_octave)\n\nif gamma is None:\n    gamma = 24.7 * alpha / 0.108\n\nif dtype is None:\n    dtype = dtype_r2c(y.dtype)\n\nfmin = fmin * 2.0 ** (tuning / bins_per_octave)\n\nfreqs = librosa.time_frequency.cqt_frequencies(n_bins, fmin, bins_per_octave=bins_per_octave)[\n    -bins_per_octave:\n]\n\nfmin_t = np.min(freqs)\nfmax_t = np.max(freqs)\n\nQ = float(filter_scale) / alpha\nfilter_cutoff = (\n    fmax_t * (1 + 0.5 * librosa.filters.window_bandwidth(window) / Q) + 0.5 * gamma\n)\nnyquist = sr / 2.0\n\nauto_resample = False\nif not res_type:\n    auto_resample = True\n    if filter_cutoff < librosa.audio.BW_FASTEST * nyquist:\n        res_type = \"kaiser_fast\"\n    else:\n        res_type = \"kaiser_best\"\n\ndownsample_count1 = max(\n    0, int(np.ceil(np.log2(librosa.audio.BW_FASTEST * nyquist / filter_cutoff)) - 1) - 1\n)\n\ndef num_two_factors(x):\n    if x <= 0:\n        return 0\n    num_twos = 0\n    while x % 2 == 0:\n        num_twos += 1\n        x //= 2\n\n    return num_twos\nnum_twos=num_two_factors(hop_length)\ndownsample_count2 = max(0, num_twos - n_octaves + 1)\ndownsample_count = min(downsample_count1, downsample_count2)\n\n\nvqt_resp = []\n\nnum_twos=num_two_factors(hop_length)\nif num_twos < n_octaves - 1:\n    raise ParameterError(\n        \"hop_length must be a positive integer \"\n        \"multiple of 2^{0:d} for {1:d}-octave CQT/VQT\".format(\n            n_octaves - 1, n_octaves\n        )\n    )\n\nmy_y, my_sr, my_hop = y, sr, hop_length\ndef sparsify_rows(x, quantile=0.01, dtype=None):\n\n    if x.ndim == 1:\n        x = x.reshape((1, -1))\n\n    elif x.ndim > 2:\n        raise ParameterError(\n            \"Input must have 2 or fewer dimensions. \"\n            \"Provided x.shape={}.\".format(x.shape)\n        )\n\n    if not 0.0 <= quantile < 1:\n        raise ParameterError(\"Invalid quantile {:.2f}\".format(quantile))\n\n    if dtype is None:\n        dtype = x.dtype\n\n    x_sparse = scipy.sparse.lil_matrix(x.shape, dtype=dtype)\n\n    mags = np.abs(x)\n    norms = np.sum(mags, axis=1, keepdims=True)\n\n    mag_sort = np.sort(mags, axis=1)\n    cumulative_mag = np.cumsum(mag_sort / norms, axis=1)\n\n    threshold_idx = np.argmin(cumulative_mag < quantile, axis=1)\n\n    for i, j in enumerate(threshold_idx):\n        idx = np.where(mags[i] >= mag_sort[i, j])\n        x_sparse[i, idx] = x[i, idx]\n\n    return x_sparse.tocsr()\n\ndef cqt_filter_fft(\n    sr,\n    fmin,\n    n_bins,\n    bins_per_octave,\n    filter_scale,\n    norm,\n    sparsity,\n    hop_length=None,\n    window=\"hann\",\n    gamma=0.0,\n    dtype=np.complex,\n):\n    basis, lengths = librosa.filters.constant_q(\n        sr,\n        fmin=fmin,\n        n_bins=n_bins,\n        bins_per_octave=bins_per_octave,\n        filter_scale=filter_scale,\n        norm=norm,\n        pad_fft=True,\n        window=window,\n    )\n\n    n_fft = basis.shape[1]\n\n    if hop_length is not None and n_fft < 2.0 ** (1 + np.ceil(np.log2(hop_length))):\n        n_fft = int(2.0 ** (1 + np.ceil(np.log2(hop_length))))\n\n    basis *= lengths[:, np.newaxis] / float(n_fft)\n\n    fft = librosa.get_fftlib()\n    fft_basis = fft.fft(basis, n=n_fft, axis=1)[:, : (n_fft // 2) + 1]\n\n    fft_basis = sparsify_rows(fft_basis, quantile=sparsity, dtype=dtype)\n\n    return fft_basis, n_fft, lengths\n\n\ndef cqt_response(y, n_fft, hop_length, fft_basis, mode, dtype=None):\n    D = librosa.stft(\n        y, n_fft=n_fft, hop_length=hop_length, window=\"ones\", pad_mode=mode, dtype=dtype\n    )\n    return fft_basis.dot(D)\n\nfor i in range(n_octaves):\n    if i > 0:\n        if len(my_y) < 2:\n            raise ParameterError(\n                \"Input signal length={} is too short for \"\n                \"{:d}-octave CQT/VQT\".format(len_orig, n_octaves)\n            )\n\n        my_y = librosa.audio.resample(my_y, 2, 1, res_type=res_type, scale=True)\n\n        my_sr /= 2.0\n        my_hop //= 2\n\n    fft_basis, n_fft, _ = cqt_filter_fft(\n        my_sr,\n        fmin_t * 2.0 ** -i,\n        n_filters,\n        bins_per_octave,\n        filter_scale,\n        norm,\n        sparsity,\n        window=window,\n        gamma=gamma,\n        dtype=dtype,\n    )\n\n    fft_basis[:] *= np.sqrt(2 ** i)\n\n    vqt_resp.append(\n        cqt_response(my_y, n_fft, my_hop, fft_basis, pad_mode, dtype=dtype)\n    )\n\ndef trim_stack(cqt_resp, n_bins, dtype):\n    max_col = min(c_i.shape[-1] for c_i in cqt_resp)\n    cqt_out = np.empty((n_bins, max_col), dtype=dtype, order=\"F\")\n\n    end = n_bins\n    for c_i in cqt_resp:\n        n_oct = c_i.shape[0]\n        if end < n_oct:\n            cqt_out[:end] = c_i[-end:, :max_col]\n        else:\n            cqt_out[end - n_oct : end] = c_i[:, :max_col]\n\n        end -= n_oct\n\n    return cqt_out\n\nV = trim_stack(vqt_resp, n_bins, dtype)\n\nif scale:\n    lengths = librosa.filters.constant_q_lengths(\n        sr,\n        fmin,\n        n_bins=n_bins,\n        bins_per_octave=bins_per_octave,\n        window=window,\n        filter_scale=filter_scale,\n    )\n    V /= np.sqrt(lengths[:, np.newaxis])\n\ntest_sol = V\nassert np.allclose(test_sol, sol)", "solution": "\n   # How many octaves are we dealing with?\n    def dtype_r2c(d, default=np.complex64):\n        \"\"\"Find the complex numpy dtype corresponding to a real dtype.\n\n        This is used to maintain numerical precision and memory footprint\n        when constructing complex arrays from real-valued data\n        (e.g. in a Fourier transform).\n\n        A `float32` (single-precision) type maps to `complex64`,\n        while a `float64` (double-precision) maps to `complex128`.\n\n\n        Parameters\n        ----------\n        d : np.dtype\n            The real-valued dtype to convert to complex.\n            If ``d`` is a complex type already, it will be returned.\n\n        default : np.dtype, optional\n            The default complex target type, if ``d`` does not match a\n            known dtype\n\n        Returns\n        -------\n        d_c : np.dtype\n            The complex dtype\n\n        See Also\n        --------\n        dtype_c2r\n        numpy.dtype\n\n        \"\"\"\n        mapping = {\n            np.dtype(np.float32): np.complex64,\n            np.dtype(np.float64): np.complex128,\n            np.dtype(np.float): np.complex,\n        }\n\n        # If we're given a complex type already, return it\n        dt = np.dtype(d)\n        if dt.kind == \"c\":\n            return dt\n\n        # Otherwise, try to map the dtype.\n        # If no match is found, return the default.\n        return np.dtype(mapping.get(dt, default))\n\n    n_octaves = int(np.ceil(float(n_bins) / bins_per_octave))\n    n_filters = min(bins_per_octave, n_bins)\n\n    len_orig = len(y)\n\n    # Relative difference in frequency between any two consecutive bands\n    alpha = 2.0 ** (1.0 / bins_per_octave) - 1\n\n    if fmin is None:\n        # C1 by default\n        fmin = librosa.note_to_hz(\"C1\")\n\n    if tuning is None:\n        tuning = librosa.pitch.estimate_tuning(y=y, sr=sr, bins_per_octave=bins_per_octave)\n\n    if gamma is None:\n        gamma = 24.7 * alpha / 0.108\n\n    if dtype is None:\n        dtype = dtype_r2c(y.dtype)\n\n    # Apply tuning correction\n    fmin = fmin * 2.0 ** (tuning / bins_per_octave)\n\n    # First thing, get the freqs of the top octave\n    freqs = librosa.time_frequency.cqt_frequencies(n_bins, fmin, bins_per_octave=bins_per_octave)[\n        -bins_per_octave:\n    ]\n\n    fmin_t = np.min(freqs)\n    fmax_t = np.max(freqs)\n\n    # Determine required resampling quality\n    Q = float(filter_scale) / alpha\n    filter_cutoff = (\n        fmax_t * (1 + 0.5 * librosa.filters.window_bandwidth(window) / Q) + 0.5 * gamma\n    )\n    nyquist = sr / 2.0\n\n    auto_resample = False\n    if not res_type:\n        auto_resample = True\n        if filter_cutoff < librosa.audio.BW_FASTEST * nyquist:\n            res_type = \"kaiser_fast\"\n        else:\n            res_type = \"kaiser_best\"\n\n    downsample_count1 = max(\n        0, int(np.ceil(np.log2(librosa.audio.BW_FASTEST * nyquist / filter_cutoff)) - 1) - 1\n    )\n\n    def num_two_factors(x):\n        if x <= 0:\n            return 0\n        num_twos = 0\n        while x % 2 == 0:\n            num_twos += 1\n            x //= 2\n\n        return num_twos\n    num_twos=num_two_factors(hop_length)\n    downsample_count2 = max(0, num_twos - n_octaves + 1)\n    downsample_count = min(downsample_count1, downsample_count2)\n\n\n    vqt_resp = []\n\n    # Make sure our hop is long enough to support the bottom octave\n\n    num_twos=num_two_factors(hop_length)\n\n\n    #num_twos = __num_two_factors(hop_length)\n    if num_twos < n_octaves - 1:\n        raise ParameterError(\n            \"hop_length must be a positive integer \"\n            \"multiple of 2^{0:d} for {1:d}-octave CQT/VQT\".format(\n                n_octaves - 1, n_octaves\n            )\n        )\n\n    # Now do the recursive bit\n    my_y, my_sr, my_hop = y, sr, hop_length\n    def sparsify_rows(x, quantile=0.01, dtype=None):\n        \"\"\"Return a row-sparse matrix approximating the input\n\n        Parameters\n        ----------\n        x : np.ndarray [ndim <= 2]\n            The input matrix to sparsify.\n\n        quantile : float in [0, 1.0)\n            Percentage of magnitude to discard in each row of ``x``\n\n        dtype : np.dtype, optional\n            The dtype of the output array.\n            If not provided, then ``x.dtype`` will be used.\n\n        Returns\n        -------\n        x_sparse : ``scipy.sparse.csr_matrix`` [shape=x.shape]\n            Row-sparsified approximation of ``x``\n\n            If ``x.ndim == 1``, then ``x`` is interpreted as a row vector,\n            and ``x_sparse.shape == (1, len(x))``.\n\n        Raises\n        ------\n        ParameterError\n            If ``x.ndim > 2``\n\n            If ``quantile`` lies outside ``[0, 1.0)``\n        \"\"\"\n\n        if x.ndim == 1:\n            x = x.reshape((1, -1))\n\n        elif x.ndim > 2:\n            raise ParameterError(\n                \"Input must have 2 or fewer dimensions. \"\n                \"Provided x.shape={}.\".format(x.shape)\n            )\n\n        if not 0.0 <= quantile < 1:\n            raise ParameterError(\"Invalid quantile {:.2f}\".format(quantile))\n\n        if dtype is None:\n            dtype = x.dtype\n\n        x_sparse = scipy.sparse.lil_matrix(x.shape, dtype=dtype)\n\n        mags = np.abs(x)\n        norms = np.sum(mags, axis=1, keepdims=True)\n\n        mag_sort = np.sort(mags, axis=1)\n        cumulative_mag = np.cumsum(mag_sort / norms, axis=1)\n\n        threshold_idx = np.argmin(cumulative_mag < quantile, axis=1)\n\n        for i, j in enumerate(threshold_idx):\n            idx = np.where(mags[i] >= mag_sort[i, j])\n            x_sparse[i, idx] = x[i, idx]\n\n        return x_sparse.tocsr()\n\n    def cqt_filter_fft(\n        sr,\n        fmin,\n        n_bins,\n        bins_per_octave,\n        filter_scale,\n        norm,\n        sparsity,\n        hop_length=None,\n        window=\"hann\",\n        gamma=0.0,\n        dtype=np.complex,\n    ):\n        \"\"\"Generate the frequency domain constant-Q filter basis.\"\"\"\n\n        basis, lengths = librosa.filters.constant_q(\n            sr,\n            fmin=fmin,\n            n_bins=n_bins,\n            bins_per_octave=bins_per_octave,\n            filter_scale=filter_scale,\n            norm=norm,\n            pad_fft=True,\n            window=window,\n        )\n\n        # Filters are padded up to the nearest integral power of 2\n        n_fft = basis.shape[1]\n\n        if hop_length is not None and n_fft < 2.0 ** (1 + np.ceil(np.log2(hop_length))):\n\n            n_fft = int(2.0 ** (1 + np.ceil(np.log2(hop_length))))\n\n        # re-normalize bases with respect to the FFT window length\n        basis *= lengths[:, np.newaxis] / float(n_fft)\n\n        # FFT and retain only the non-negative frequencies\n        fft = librosa.get_fftlib()\n        fft_basis = fft.fft(basis, n=n_fft, axis=1)[:, : (n_fft // 2) + 1]\n\n        # sparsify the basis\n        fft_basis = sparsify_rows(fft_basis, quantile=sparsity, dtype=dtype)\n\n        return fft_basis, n_fft, lengths\n\n\n    def cqt_response(y, n_fft, hop_length, fft_basis, mode, dtype=None):\n        \"\"\"Compute the filter response with a target STFT hop.\"\"\"\n\n        # Compute the STFT matrix\n        D = librosa.stft(\n            y, n_fft=n_fft, hop_length=hop_length, window=\"ones\", pad_mode=mode, dtype=dtype\n        )\n\n        # And filter response energy\n        return fft_basis.dot(D)\n\n    # Iterate down the octaves\n    for i in range(n_octaves):\n        # Resample (except first time)\n        if i > 0:\n            if len(my_y) < 2:\n                raise ParameterError(\n                    \"Input signal length={} is too short for \"\n                    \"{:d}-octave CQT/VQT\".format(len_orig, n_octaves)\n                )\n\n            my_y = librosa.audio.resample(my_y, 2, 1, res_type=res_type, scale=True)\n\n            my_sr /= 2.0\n            my_hop //= 2\n\n        fft_basis, n_fft, _ = cqt_filter_fft(\n            my_sr,\n            fmin_t * 2.0 ** -i,\n            n_filters,\n            bins_per_octave,\n            filter_scale,\n            norm,\n            sparsity,\n            window=window,\n            gamma=gamma,\n            dtype=dtype,\n        )\n\n        # Re-scale the filters to compensate for downsampling\n        fft_basis[:] *= np.sqrt(2 ** i)\n\n        # Compute the vqt filter response and append to the stack\n        vqt_resp.append(\n            cqt_response(my_y, n_fft, my_hop, fft_basis, pad_mode, dtype=dtype)\n        )\n\n    def trim_stack(cqt_resp, n_bins, dtype):\n        \"\"\"Helper function to trim and stack a collection of CQT responses\"\"\"\n\n        max_col = min(c_i.shape[-1] for c_i in cqt_resp)\n        cqt_out = np.empty((n_bins, max_col), dtype=dtype, order=\"F\")\n\n        # Copy per-octave data into output array\n        end = n_bins\n        for c_i in cqt_resp:\n            # By default, take the whole octave\n            n_oct = c_i.shape[0]\n            # If the whole octave is more than we can fit,\n            # take the highest bins from c_i\n            if end < n_oct:\n                cqt_out[:end] = c_i[-end:, :max_col]\n            else:\n                cqt_out[end - n_oct : end] = c_i[:, :max_col]\n\n            end -= n_oct\n\n        return cqt_out\n\n    V = trim_stack(vqt_resp, n_bins, dtype)\n\n    if scale:\n        lengths = librosa.filters.constant_q_lengths(\n            sr,\n            fmin,\n            n_bins=n_bins,\n            bins_per_octave=bins_per_octave,\n            window=window,\n            filter_scale=filter_scale,\n        )\n        V /= np.sqrt(lengths[:, np.newaxis])\n    return V", "type_of_change": "new feature", "name_of_class_or_func": "librosa.vqt", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.8.0", "problem": "Complete the function to compute the variable-Q transform of an audio signal.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Union, Optional\n\nDTypeLike = Union[np.dtype, type]\n\n\ndef compute_vqt(y: np.ndarray, sr: int) -> np.ndarray:\n    ", "example_id": "311", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\n\nsol = compute_vqt(y, sr)\ntest_sol = librosa.vqt(y, sr=sr)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    return librosa.vqt(y, sr=sr)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.vqt", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to compute the approximate constant-Q magnitude spectrogram inversion using the \u201cfast\u201d Griffin-Lim algorithm.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Union, Optional\n\nDTypeLike = Union[np.dtype, type]\n\ndef compute_griffinlim_cqt(y: np.ndarray, sr: int, C, n_iter: int, hop_length: int, fmin: int, bins_per_octave: int, tuning: float, filter_scale: 1, norm: int, sparsity: float, window: str, scale: bool, pad_mode: str, res_type: str, dtype: DTypeLike, length: Optional[int], momentum: float, init: Optional[str]) -> np.ndarray:\n    rng = np.random.RandomState(seed=0)", "example_id": "312", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\ny=y[:10000]\n\nC = np.abs(librosa.cqt(y=y, sr=sr, bins_per_octave=36, n_bins=7*36))\nn_iter=32\nhop_length=512\nfmin=None\nbins_per_octave=36\ntuning=0.0\nfilter_scale=1\nnorm=1\nsparsity=0.01\nwindow=\"hann\"\nscale=True\npad_mode=\"reflect\"\nres_type=\"kaiser_fast\"\ndtype=None\nlength=None\nmomentum=0.99\ninit=None\nrng = np.random.RandomState(seed=0)\nsol = compute_griffinlim_cqt(y, sr, C, n_iter, hop_length, fmin, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype, length, momentum, init)\n\nif fmin is None:\n    fmin = librosa.note_to_hz(\"C1\")\n\nangles = np.empty(C.shape, dtype=np.complex64)\nif init == \"random\":\n    angles[:] = np.exp(2j * np.pi * rng.rand(*C.shape))\nelif init is None:\n    angles[:] = 1.0\nrebuilt = 0.0\n\nfor _ in range(n_iter):\n    tprev = rebuilt\n\n    inverse = librosa.constantq.icqt(\n    C * angles,\n    sr=sr,\n    hop_length=hop_length,\n    bins_per_octave=bins_per_octave,\n    fmin=fmin,\n    tuning=tuning,\n    filter_scale=filter_scale,\n    window=window,\n    length=length,\n    res_type=res_type,\n    )\n\n    rebuilt = librosa.constantq.cqt(\n    inverse,\n    sr=sr,\n    bins_per_octave=bins_per_octave,\n    n_bins=C.shape[0],\n    hop_length=hop_length,\n    fmin=fmin,\n    tuning=tuning,\n    filter_scale=filter_scale,\n    window=window,\n    res_type=res_type,\n    )\n    angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n    angles[:] /= np.abs(angles) + 1e-16\n\ntest_sol = librosa.constantq.icqt(\n C * angles,\n sr=sr,\n hop_length=hop_length,\n bins_per_octave=bins_per_octave,\n tuning=tuning,\n filter_scale=filter_scale,\n fmin=fmin,\n window=window,\n length=length,\n res_type=res_type,\n)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    if fmin is None:\n        fmin = librosa.note_to_hz(\"C1\")\n    \n    angles = np.empty(C.shape, dtype=np.complex64)\n    if init == \"random\":\n        angles[:] = np.exp(2j * np.pi * rng.rand(*C.shape))\n    elif init is None:\n        angles[:] = 1.0\n    \n    rebuilt = 0.0\n    \n    for _ in range(n_iter):\n        tprev = rebuilt\n    \n        inverse = librosa.constantq.icqt(\n        C * angles,\n        sr=sr,\n        hop_length=hop_length,\n        bins_per_octave=bins_per_octave,\n        fmin=fmin,\n        tuning=tuning,\n        filter_scale=filter_scale,\n        window=window,\n        length=length,\n        res_type=res_type,\n        )\n    \n        rebuilt = librosa.constantq.cqt(\n        inverse,\n        sr=sr,\n        bins_per_octave=bins_per_octave,\n        n_bins=C.shape[0],\n        hop_length=hop_length,\n        fmin=fmin,\n        tuning=tuning,\n        filter_scale=filter_scale,\n        window=window,\n        res_type=res_type,\n        )\n    \n        angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n        angles[:] /= np.abs(angles) + 1e-16\n    \n    return  librosa.constantq.icqt(\n     C * angles,\n     sr=sr,\n     hop_length=hop_length,\n     bins_per_octave=bins_per_octave,\n     tuning=tuning,\n     filter_scale=filter_scale,\n     fmin=fmin,\n     window=window,\n     length=length,\n     res_type=res_type,\n    )\n    ", "type_of_change": "new feature", "name_of_class_or_func": "librosa.griffinlim_cqt", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.8.0", "problem": "Complete the function to compute the approximate constant-Q magnitude spectrogram inversion using the \u201cfast\u201d Griffin-Lim algorithm.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nfrom typing import Union, Optional\n\nDTypeLike = Union[np.dtype, type]\n\ndef compute_griffinlim_cqt(y: np.ndarray, sr: int, C, n_iter: int, hop_length: int, fmin: int, bins_per_octave: int, tuning: float, filter_scale: 1, norm: int, sparsity: float, window: str, scale: bool, pad_mode: str, res_type: str, dtype: DTypeLike, length: Optional[int], momentum: float, init: Optional[str]) -> np.ndarray:\n    rng = np.random.RandomState(seed=0)", "example_id": "313", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\ny=y[:10000]\n\nC = np.abs(librosa.cqt(y=y, sr=sr, bins_per_octave=36, n_bins=7*36))\nn_iter=32\nhop_length=512\nfmin=None\nbins_per_octave=36\ntuning=0.0\nfilter_scale=1\nnorm=1\nsparsity=0.01\nwindow=\"hann\"\nscale=True\npad_mode=\"reflect\"\nres_type=\"kaiser_fast\"\ndtype=None\nlength=None\nmomentum=0.99\ninit=None\nrng = np.random.RandomState(seed=0)\nsol = compute_griffinlim_cqt(y, sr, C, n_iter, hop_length, fmin, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype, length, momentum, init)\n\nif fmin is None:\n    fmin = librosa.note_to_hz(\"C1\")\n\nangles = np.empty(C.shape, dtype=np.complex64)\nif init == \"random\":\n    angles[:] = np.exp(2j * np.pi * rng.rand(*C.shape))\nelif init is None:\n    angles[:] = 1.0\nrebuilt = 0.0\n\nfor _ in range(n_iter):\n    tprev = rebuilt\n\n    inverse = librosa.constantq.icqt(\n    C * angles,\n    sr=sr,\n    hop_length=hop_length,\n    bins_per_octave=bins_per_octave,\n    fmin=fmin,\n    tuning=tuning,\n    filter_scale=filter_scale,\n    window=window,\n    length=length,\n    res_type=res_type,\n    )\n\n    rebuilt = librosa.constantq.cqt(\n    inverse,\n    sr=sr,\n    bins_per_octave=bins_per_octave,\n    n_bins=C.shape[0],\n    hop_length=hop_length,\n    fmin=fmin,\n    tuning=tuning,\n    filter_scale=filter_scale,\n    window=window,\n    res_type=res_type,\n    )\n    angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n    angles[:] /= np.abs(angles) + 1e-16\n\ntest_sol = librosa.constantq.icqt(\n C * angles,\n sr=sr,\n hop_length=hop_length,\n bins_per_octave=bins_per_octave,\n tuning=tuning,\n filter_scale=filter_scale,\n fmin=fmin,\n window=window,\n length=length,\n res_type=res_type,\n)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    return librosa.griffinlim_cqt(C, sr=sr, bins_per_octave=bins_per_octave, init=init)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.griffinlim_cqt", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to invert a mel power spectrogram to audio using Griffin-Lim.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nimport scipy.optimize\nfrom typing import Union, Optional\n\nDTypeLike = Union[np.dtype, type]\n\n\ndef compute_mel_to_audio(y: np.ndarray, sr: int, S: np.ndarray, M: np.ndarray, n_fft: int, hop_length: Optional[int], win_length: Optional[int], window: str, center: bool, pad_mode: str, power: float, n_iter: int, length: Optional[int], dtype: DTypeLike) -> np.ndarray:\n    np.random.seed(seed=0)", "example_id": "314", "test": "filename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\ny=y[:10000]\n\nS = np.abs(librosa.stft(y))**2\nM = librosa.feature.melspectrogram(y=y, sr=sr, S=S)\nn_fft=2048\nhop_length=512\nwin_length=None\nwindow='hann'\ncenter=True\npad_mode='reflect'\npower=2.0\nn_iter=32\nlength=None\ndtype=np.float32\nnp.random.seed(seed=0)\nsol =  compute_mel_to_audio(y, sr, S, M, n_fft, hop_length, win_length, window, center, pad_mode, power, n_iter, length, dtype)\nnp.random.seed(seed=0)\n\ndef _nnls_obj(x, shape, A, B):\n    x = x.reshape(shape)\n\n    diff = np.dot(A, x) - B\n\n    value = 0.5 * np.sum(diff**2)\n\n    grad = np.dot(A.T, diff)\n\n    return value, grad.flatten()\n\n\ndef _nnls_lbfgs_block(A, B, x_init=None, **kwargs):\n    if x_init is None:\n        x_init = np.linalg.lstsq(A, B, rcond=None)[0]\n        np.clip(x_init, 0, None, out=x_init)\n\n    kwargs.setdefault('m', A.shape[1])\n\n    bounds = [(0, None)] * x_init.size\n    shape = x_init.shape\n\n    x, obj_value, diagnostics = scipy.optimize.fmin_l_bfgs_b(_nnls_obj, x_init,\n                                                             args=(shape, A, B),\n                                                             bounds=bounds,\n                                                             **kwargs)\n    return x.reshape(shape)\n\n\ndef nnls(A, B, **kwargs):\n    if B.ndim == 1:\n        return scipy.optimize.nnls(A, B)[0]\n\n    n_columns = int((2**8 * 2**10)// (A.shape[-1] * A.itemsize))\n\n    if B.shape[-1] <= n_columns:\n        return _nnls_lbfgs_block(A, B, **kwargs).astype(A.dtype)\n\n    x = np.linalg.lstsq(A, B, rcond=None)[0].astype(A.dtype)\n    np.clip(x, 0, None, out=x)\n    x_init = x\n\n    for bl_s in range(0, x.shape[-1], n_columns):\n        bl_t = min(bl_s + n_columns, B.shape[-1])\n        x[:, bl_s:bl_t] = _nnls_lbfgs_block(A, B[:, bl_s:bl_t],\n                                            x_init=x_init[:, bl_s:bl_t],\n                                            **kwargs)\n    return x\n\nrng = np.random.seed(seed=0)\ndef mel_to_stft(M, sr=22050, n_fft=2048, power=2.0, **kwargs):\n    mel_basis = librosa.filters.mel(sr, n_fft, n_mels=M.shape[0],\n                            **kwargs)\n    inverse = nnls(mel_basis, M)\n    return np.power(inverse, 1./power, out=inverse)\n\n\nstft = mel_to_stft(M, sr=sr, n_fft=n_fft, power=power)\ndef griffinlim(S, n_iter=32, hop_length=None, win_length=None, window='hann', \n               center=True, dtype=np.float32, length=None, pad_mode='reflect',\n               momentum=0.99, random_state=None):\n    rng = np.random\n    n_fft = 2 * (S.shape[0] - 1)\n\n    angles = np.exp(2j * np.pi * rng.rand(*S.shape))\n\n    rebuilt = 0.\n\n    for _ in range(n_iter):\n        tprev = rebuilt\n        inverse = librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n                         window=window, center=center, dtype=dtype, length=length)\n        rebuilt = librosa.stft(inverse, n_fft=n_fft, hop_length=hop_length,win_length=win_length, window=window, center=center, pad_mode=pad_mode)\n\n        angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n        angles[:] /= np.abs(angles) + 1e-16\n    return librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n                 window=window, center=center, dtype=dtype, length=length)\ntest_sol = griffinlim(stft, n_iter=n_iter, hop_length=hop_length, win_length=win_length,\n                      window=window, center=center, dtype=dtype, length=length,\n                      pad_mode=pad_mode)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    def _nnls_obj(x, shape, A, B):\n        x = x.reshape(shape)\n\n        diff = np.dot(A, x) - B\n\n        value = 0.5 * np.sum(diff**2)\n\n        grad = np.dot(A.T, diff)\n\n        return value, grad.flatten()\n\n\n    def _nnls_lbfgs_block(A, B, x_init=None, **kwargs):\n        if x_init is None:\n            x_init = np.linalg.lstsq(A, B, rcond=None)[0]\n            np.clip(x_init, 0, None, out=x_init)\n\n        kwargs.setdefault('m', A.shape[1])\n\n        bounds = [(0, None)] * x_init.size\n        shape = x_init.shape\n\n        x, obj_value, diagnostics = scipy.optimize.fmin_l_bfgs_b(_nnls_obj, x_init,\n                                                                 args=(shape, A, B),\n                                                                 bounds=bounds,\n                                                                 **kwargs)\n        return x.reshape(shape)\n\n\n    def nnls(A, B, **kwargs):\n        if B.ndim == 1:\n            return scipy.optimize.nnls(A, B)[0]\n\n        n_columns = int((2**8 * 2**10)// (A.shape[-1] * A.itemsize))\n\n        if B.shape[-1] <= n_columns:\n            return _nnls_lbfgs_block(A, B, **kwargs).astype(A.dtype)\n\n        x = np.linalg.lstsq(A, B, rcond=None)[0].astype(A.dtype)\n        np.clip(x, 0, None, out=x)\n        x_init = x\n\n        for bl_s in range(0, x.shape[-1], n_columns):\n            bl_t = min(bl_s + n_columns, B.shape[-1])\n            x[:, bl_s:bl_t] = _nnls_lbfgs_block(A, B[:, bl_s:bl_t],\n                                                x_init=x_init[:, bl_s:bl_t],\n                                                **kwargs)\n        return x\n\n    rng = np.random.seed(seed=0)\n    def mel_to_stft(M, sr=22050, n_fft=2048, power=2.0, **kwargs):\n        mel_basis = librosa.filters.mel(sr, n_fft, n_mels=M.shape[0],\n                                **kwargs)\n\n        inverse = nnls(mel_basis, M)\n        return np.power(inverse, 1./power, out=inverse)\n\n\n    stft = mel_to_stft(M, sr=sr, n_fft=n_fft, power=power)\n    def griffinlim(S, n_iter=32, hop_length=None, win_length=None, window='hann', \n                   center=True, dtype=np.float32, length=None, pad_mode='reflect',\n                   momentum=0.99, random_state=None):\n        rng = np.random\n        n_fft = 2 * (S.shape[0] - 1)\n\n        angles = np.exp(2j * np.pi * rng.rand(*S.shape))\n\n        rebuilt = 0.\n\n        for _ in range(n_iter):\n            tprev = rebuilt\n            inverse = librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n                             window=window, center=center, dtype=dtype, length=length)\n            rebuilt = librosa.stft(inverse, n_fft=n_fft, hop_length=hop_length,win_length=win_length, window=window, center=center, pad_mode=pad_mode)\n\n            angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n            angles[:] /= np.abs(angles) + 1e-16\n        return librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n                     window=window, center=center, dtype=dtype, length=length)\n    return griffinlim(stft, n_iter=n_iter, hop_length=hop_length, win_length=win_length,\n                          window=window, center=center, dtype=dtype, length=length,\n                          pad_mode=pad_mode)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.feature.inverse.mel_to_audio", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to invert a mel power spectrogram to audio using Griffin-Lim.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\nimport scipy.optimize\nfrom typing import Union, Optional\n\nDTypeLike = Union[np.dtype, type]\n\n\ndef compute_mel_to_audio(y: np.ndarray, sr: int, S: np.ndarray, M: np.ndarray, n_fft: int, hop_length: Optional[int], win_length: Optional[int], window: str, center: bool, pad_mode: str, power: float, n_iter: int, length: Optional[int], dtype: DTypeLike) -> np.ndarray:\n    np.random.seed(seed=0)", "example_id": "315", "test": "filename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\ny=y[:10000]\n\nS = np.abs(librosa.stft(y))**2\nM = librosa.feature.melspectrogram(y=y, sr=sr, S=S)\nn_fft=2048\nhop_length=512\nwin_length=None\nwindow='hann'\ncenter=True\npad_mode='reflect'\npower=2.0\nn_iter=32\nlength=None\ndtype=np.float32\nnp.random.seed(seed=0)\nsol =  compute_mel_to_audio(y, sr, S, M, n_fft, hop_length, win_length, window, center, pad_mode, power, n_iter, length, dtype)\nnp.random.seed(seed=0)\n\ndef _nnls_obj(x, shape, A, B):\n    x = x.reshape(shape)\n\n    diff = np.dot(A, x) - B\n\n    value = 0.5 * np.sum(diff**2)\n\n    grad = np.dot(A.T, diff)\n\n    return value, grad.flatten()\n\n\ndef _nnls_lbfgs_block(A, B, x_init=None, **kwargs):\n    if x_init is None:\n        x_init = np.linalg.lstsq(A, B, rcond=None)[0]\n        np.clip(x_init, 0, None, out=x_init)\n\n    kwargs.setdefault('m', A.shape[1])\n\n    bounds = [(0, None)] * x_init.size\n    shape = x_init.shape\n\n    x, obj_value, diagnostics = scipy.optimize.fmin_l_bfgs_b(_nnls_obj, x_init,\n                                                             args=(shape, A, B),\n                                                             bounds=bounds,\n                                                             **kwargs)\n    return x.reshape(shape)\n\n\ndef nnls(A, B, **kwargs):\n    if B.ndim == 1:\n        return scipy.optimize.nnls(A, B)[0]\n\n    n_columns = int((2**8 * 2**10)// (A.shape[-1] * A.itemsize))\n\n    if B.shape[-1] <= n_columns:\n        return _nnls_lbfgs_block(A, B, **kwargs).astype(A.dtype)\n\n    x = np.linalg.lstsq(A, B, rcond=None)[0].astype(A.dtype)\n    np.clip(x, 0, None, out=x)\n    x_init = x\n\n    for bl_s in range(0, x.shape[-1], n_columns):\n        bl_t = min(bl_s + n_columns, B.shape[-1])\n        x[:, bl_s:bl_t] = _nnls_lbfgs_block(A, B[:, bl_s:bl_t],\n                                            x_init=x_init[:, bl_s:bl_t],\n                                            **kwargs)\n    return x\n\nrng = np.random.seed(seed=0)\ndef mel_to_stft(M, sr=22050, n_fft=2048, power=2.0, **kwargs):\n    mel_basis = librosa.filters.mel(sr, n_fft, n_mels=M.shape[0],\n                            **kwargs)\n    inverse = nnls(mel_basis, M)\n    return np.power(inverse, 1./power, out=inverse)\n\n\nstft = mel_to_stft(M, sr=sr, n_fft=n_fft, power=power)\ndef griffinlim(S, n_iter=32, hop_length=None, win_length=None, window='hann', \n               center=True, dtype=np.float32, length=None, pad_mode='reflect',\n               momentum=0.99, random_state=None):\n    rng = np.random\n    n_fft = 2 * (S.shape[0] - 1)\n\n    angles = np.exp(2j * np.pi * rng.rand(*S.shape))\n\n    rebuilt = 0.\n\n    for _ in range(n_iter):\n        tprev = rebuilt\n        inverse = librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n                         window=window, center=center, dtype=dtype, length=length)\n        rebuilt = librosa.stft(inverse, n_fft=n_fft, hop_length=hop_length,win_length=win_length, window=window, center=center, pad_mode=pad_mode)\n\n        angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n        angles[:] /= np.abs(angles) + 1e-16\n    return librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n                 window=window, center=center, dtype=dtype, length=length)\ntest_sol = griffinlim(stft, n_iter=n_iter, hop_length=hop_length, win_length=win_length,\n                      window=window, center=center, dtype=dtype, length=length,\n                      pad_mode=pad_mode)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    return librosa.feature.inverse.mel_to_audio(M)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.feature.inverse.mel_to_audio", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.6.0", "problem": "Complete the function to invert Mel-frequency cepstral coefficients to approximate a Mel power spectrogram.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\n\ndef compute_mfcc_to_mel(mfcc: np.ndarray, n_mels: int=128, dct_type: int=2, norm: str='ortho', ref: float=1.0) -> np.ndarray:\n    \"\"\"\n    Invert Mel-frequency cepstral coefficients to approximate a Mel power spectrogram.\n\n    Parameters:\n        mfcc (np.ndarray): Mel-frequency cepstral coefficients.\n        n_mels (int): Number of Mel bands to generate.\n        dct_type (int): Type of DCT to use.\n        norm (str): Normalization to use.\n        ref: Reference power for (inverse) decibel calculation\n\n    Returns:\n        An approximate Mel power spectrum recovered from mfcc.        \n    \"\"\"\n    np.random.seed(seed=0)", "example_id": "316", "test": "filename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nmfcc = librosa.feature.mfcc(y=y, sr=sr)\n\nsol =  compute_mfcc_to_mel(mfcc)\ndef mfcc_to_mel(mfcc, n_mels=128, dct_type=2, norm='ortho', ref=1.0):\n    logmel = scipy.fftpack.idct(mfcc, axis=0, type=dct_type, norm=norm, n=n_mels)\n    return librosa.db_to_power(logmel, ref=ref)\n\nnp.random.seed(seed=0)\ntest_sol = mfcc_to_mel(mfcc)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    logmel = scipy.fftpack.idct(mfcc, axis=0, type=dct_type, norm=norm, n=n_mels)\n    return librosa.db_to_power(logmel, ref=ref)\n", "type_of_change": "new feature", "name_of_class_or_func": "librosa.feature.inverse.mfcc_to_mel", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "librosa", "version": "0.7.0", "problem": "Complete the function to invert Mel-frequency cepstral coefficients to approximate a Mel power spectrogram.", "starting_code": "import librosa\nimport numpy as np\nimport scipy\n\ndef compute_mfcc_to_mel(mfcc: np.ndarray, n_mels: int=128, dct_type: int=2, norm: str='ortho', ref: float=1.0) -> np.ndarray:\n    \"\"\"\n    Invert Mel-frequency cepstral coefficients to approximate a Mel power spectrogram.\n\n    Parameters:\n        mfcc (np.ndarray): Mel-frequency cepstral coefficients.\n        n_mels (int): Number of Mel bands to generate.\n        dct_type (int): Type of DCT to use.\n        norm (str): Normalization to use.\n        ref: Reference power for (inverse) decibel calculation\n\n    Returns:\n        An approximate Mel power spectrum recovered from mfcc.        \n    \"\"\"    \n    np.random.seed(seed=0)", "example_id": "317", "test": "\nfilename = librosa.util.example_audio_file()\ny, sr = librosa.load(filename)\nmfcc = librosa.feature.mfcc(y=y, sr=sr)\n\nsol = compute_mfcc_to_mel(mfcc)\n\nnp.random.seed(seed=0)\ntest_sol = librosa.feature.inverse.mfcc_to_mel(mfcc)\nassert np.allclose(test_sol, sol)", "solution": "\n\n    return librosa.feature.inverse.mfcc_to_mel(mfcc)", "type_of_change": "new feature", "name_of_class_or_func": "librosa.feature.inverse.mfcc_to_mel", "additional_dependencies": "pip==24.0 numba==0.46 llvmlite==0.30 joblib==0.14 numpy==1.16.0 audioread==2.1.5 scipy==1.1.0 resampy==0.2.2 soundfile==0.10.2"}
{"python_version": "3.7", "library": "pillow", "version": "7.0.0", "problem": "Implement the function to superimpose two images on top of each other using the Overlay algorithm.", "starting_code": "import numpy as np\nfrom PIL import Image, ImageChops\n\n\ndef imaging(img1: Image, img2: Image) -> Image:\n    ", "example_id": "318", "test": "def generate_random_image(width, height):\n    random_data = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n    return Image.fromarray(random_data)\n\ndef create(imIn1, imIn2, mode=None):\n    if imIn1.shape != imIn2.shape:\n        return None\n    return np.empty_like(imIn1, dtype=np.uint8)\n\ndef imaging_overlay(imIn1, imIn2):\n    imOut = create(imIn1, imIn2)\n    if imOut is None:\n        return None\n    \n    ysize, xsize, _ = imOut.shape\n    for y in range(ysize):\n        for x in range(xsize):\n            for c in range(3):  # Loop over RGB channels\n                in1, in2 = int(imIn1[y, x, c]), int(imIn2[y, x, c])\n                if in1 < 128:\n                    imOut[y, x, c] = np.clip((in1 * in2) // 127, 0, 255)\n                else:\n                    imOut[y, x, c] = np.clip(255 - (((255 - in1) * (255 - in2)) // 127), 0, 255)\n    \n    return imOut\n\nwidth, height = 256, 256\nimg1 = generate_random_image(width, height)\nimg2 = generate_random_image(width, height)\ngt = imaging_overlay(np.array(img1), np.array(img2))\nsol = imaging(img1, img2)\nassert np.allclose(np.array(gt), np.array(sol))", "solution": "\n\n    def create(imIn1, imIn2, mode=None):\n        if imIn1.shape != imIn2.shape:\n            return None\n        return np.empty_like(imIn1, dtype=np.uint8)\n\n    def imaging_overlay(imIn1, imIn2):\n        imOut = create(imIn1, imIn2)\n        if imOut is None:\n            return None\n        \n        ysize, xsize, _ = imOut.shape\n        for y in range(ysize):\n            for x in range(xsize):\n                for c in range(3):  # Loop over RGB channels\n                    in1, in2 = int(imIn1[y, x, c]), int(imIn2[y, x, c])\n                    if in1 < 128:\n                        imOut[y, x, c] = np.clip((in1 * in2) // 127, 0, 255)\n                    else:\n                        imOut[y, x, c] = np.clip(255 - (((255 - in1) * (255 - in2)) // 127), 0, 255)\n        \n        return imOut\n\n    return imaging_overlay(np.array(img1), np.array(img2))", "type_of_change": "new feature", "name_of_class_or_func": "PIL.ImageChops.overlay", "additional_dependencies": "numpy==1.16"}
{"python_version": "3.7", "library": "pillow", "version": "7.0.0", "problem": "Implement the function to superimpose two images on top of each other using the Soft Light algorithm.", "starting_code": "import numpy as np\nfrom PIL import Image, ImageChops\n\ndef imaging(img1: Image, img2: Image) -> Image:\n    ", "example_id": "319", "test": "\ndef generate_random_image(width, height):\n    random_data = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n    return Image.fromarray(random_data)\n\ndef create(imIn1, imIn2, mode=None):\n    if imIn1.shape != imIn2.shape:\n        return None\n    return np.empty_like(imIn1, dtype=np.uint8)\n\ndef imaging_softlight(imIn1, imIn2):\n    if imIn1.shape != imIn2.shape:\n        return None\n  \n    imOut = create(imIn1, imIn2)\n    ysize, xsize, _ = imOut.shape\n    for y in range(ysize):\n        for x in range(xsize):\n            for c in range(3):  # Loop over RGB channels\n                in1, in2 = int(imIn1[y, x, c]), int(imIn2[y, x, c])\n                imOut[y, x, c] = int((((255 - in1) * (in1 * in2)) // 65536) +  (in1 * (255 - ((255 - in1) * (255 - in2) // 255))) // 255)\n    return imOut\n\nwidth, height = 256, 256\nimg1 = generate_random_image(width, height)\nimg2 = generate_random_image(width, height)\n\n\ngt = imaging_softlight(np.array(img1), np.array(img2))\nsol = imaging(img1, img2)\nassert np.allclose(np.array(gt), np.array(sol))", "solution": "\n\n    def create(imIn1, imIn2, mode=None):\n        if imIn1.shape != imIn2.shape:\n            return None\n        return np.empty_like(imIn1, dtype=np.uint8)\n\n    def imaging_softlight(imIn1, imIn2):\n        if imIn1.shape != imIn2.shape:\n            return None\n        \n        imOut = create(imIn1, imIn2)\n        ysize, xsize, _ = imOut.shape\n        for y in range(ysize):\n            for x in range(xsize):\n                for c in range(3):  # Loop over RGB channels\n                    in1, in2 = int(imIn1[y, x, c]), int(imIn2[y, x, c])\n                    imOut[y, x, c] = int((((255 - in1) * (in1 * in2)) // 65536) +  (in1 * (255 - ((255 - in1) * (255 - in2) // 255))) // 255)\n        return imOut\n    return imaging_softlight(np.array(img1), np.array(img2))", "type_of_change": "new feature", "name_of_class_or_func": "PIL.ImageChops.soft_light", "additional_dependencies": "numpy==1.16"}
{"python_version": "3.7", "library": "pillow", "version": "7.0.0", "problem": "Implement the function to superimpose two images on top of each other using the Hard Light algorithm. ", "starting_code": "import numpy as np\nfrom PIL import Image, ImageChops\n\n\ndef imaging(img1: Image, img2: Image) -> Image:\n    ", "example_id": "320", "test": "\ndef generate_random_image(width, height):\n    random_data = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n    return Image.fromarray(random_data)\nwidth, height = 256, 256\nimg1 = generate_random_image(width, height)\nimg2 = generate_random_image(width, height)\n\n\n\ndef create(imIn1, imIn2, mode=None):\n    if imIn1.shape != imIn2.shape:\n        return None\n    return np.empty_like(imIn1, dtype=np.uint8)\n\ndef imaging_hardlight(imIn1, imIn2):\n    imOut = create(imIn1, imIn2)\n    if imOut is None:\n        return None\n    \n    ysize, xsize, _ = imOut.shape\n    for y in range(ysize):\n        for x in range(xsize):\n            for c in range(3):  # Loop over RGB channels\n                in1, in2 = int(imIn2[y, x, c]), int(imIn1[y, x, c])\n                if in1 < 128:\n                    imOut[y, x, c] = np.clip((in1 * in2) // 127, 0, 255)\n                else:\n                    imOut[y, x, c] = np.clip(255 - (((255 - in1) * (255 - in2)) // 127), 0, 255)\n    \n    return imOut\n\ngt = imaging_hardlight(np.array(img1), np.array(img2))\nsol = imaging(img1, img2)\nassert np.allclose(np.array(gt), np.array(sol))", "solution": "\n\n    def create(imIn1, imIn2, mode=None):\n        if imIn1.shape != imIn2.shape:\n            return None\n        return np.empty_like(imIn1, dtype=np.uint8)\n\n    def imaging_hardlight(imIn1, imIn2):\n        imOut = create(imIn1, imIn2)\n        if imOut is None:\n            return None\n        \n        ysize, xsize, _ = imOut.shape\n        for y in range(ysize):\n            for x in range(xsize):\n                for c in range(3):  # Loop over RGB channels\n                    in1, in2 = int(imIn2[y, x, c]), int(imIn1[y, x, c])\n                    if in1 < 128:\n                        imOut[y, x, c] = np.clip((in1 * in2) // 127, 0, 255)\n                    else:\n                        imOut[y, x, c] = np.clip(255 - (((255 - in1) * (255 - in2)) // 127), 0, 255)\n        \n        return imOut\n\n    return imaging_hardlight(np.array(img1), np.array(img2))", "type_of_change": "new feature", "name_of_class_or_func": "PIL.ImageChops.hard_light", "additional_dependencies": "numpy==1.16"}
{"python_version": "3.7", "library": "pillow", "version": "7.1.0", "problem": "Implement the function to superimpose two images on top of each other using the Overlay algorithm.", "starting_code": "import numpy as np\nfrom PIL import Image, ImageChops\n\n\ndef imaging(img1: Image, img2: Image) -> Image:\n    ", "example_id": "321", "test": "import numpy as np\nfrom PIL import Image, ImageChops\n\ndef generate_random_image(width, height):\n random_data = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n return Image.fromarray(random_data)\nwidth, height = 256, 256\nimg1 = generate_random_image(width, height)\nimg2 = generate_random_image(width, height)\n\ngt = ImageChops.overlay(img1, img2)\nsol = imaging(img1, img2)\nassert np.allclose(np.array(gt), np.array(sol))", "solution": "\n    return ImageChops.overlay(img1, img2)", "type_of_change": "new feature", "name_of_class_or_func": "PIL.ImageChops.overlay", "additional_dependencies": "numpy==1.16"}
{"python_version": "3.7", "library": "pillow", "version": "7.1.0", "problem": "Implement a function to superimpose two images on top of each other using the Soft Light algorithm.", "starting_code": "import numpy as np\nfrom PIL import Image, ImageChops\n\ndef imaging(img1: Image, img2: Image) -> Image:", "example_id": "322", "test": "def generate_random_image(width, height):\n random_data = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n return Image.fromarray(random_data)\nwidth, height = 256, 256\nimg1 = generate_random_image(width, height)\nimg2 = generate_random_image(width, height)\n\ngt = ImageChops.soft_light(img1, img2)\nsol = imaging(img1, img2)\nassert np.allclose(np.array(sol), np.array(sol))", "solution": "\n    return ImageChops.soft_light(img1, img2)", "type_of_change": "new feature", "name_of_class_or_func": "PIL.ImageChops.soft_light", "additional_dependencies": "numpy==1.16"}
{"python_version": "3.7", "library": "pillow", "version": "7.1.0", "problem": "Implement the function to superimpose two images on top of each other using the Hard Light algorithm.", "starting_code": "import numpy as np\nfrom PIL import Image, ImageChops\n\ndef imaging(img1: Image, img2: Image) -> Image:", "example_id": "323", "test": "def generate_random_image(width, height):\n random_data = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n return Image.fromarray(random_data)\n\nwidth, height = 256, 256\nimg1 = generate_random_image(width, height)\nimg2 = generate_random_image(width, height)\n\n\ngt = ImageChops.hard_light(img1, img2)\nsol = imaging(img1, img2)\nassert np.allclose(np.array(gt), np.array(sol))", "solution": "\n    return ImageChops.hard_light(img1, img2)", "type_of_change": "new feature", "name_of_class_or_func": "PIL.ImageChops.hard_light", "additional_dependencies": "numpy==1.16"}
{"python_version": "3.7", "library": "tqdm", "version": "4.28", "problem": "Iterate over an infinite iterable.", "starting_code": "from tqdm import tqdm\n\ndef infinite():\n    i = 0\n    while True:\n        yield i\n        i += 1\n        if i == 1000:\n          return\n\n# Define the total in sol_dict['total'] and use it.\nsol_dict = {\"total\":0}", "example_id": "324", "test": "assert sol_dict['total'] is None", "solution": "\nsol_dict['total'] = None\nprogress_bar = tqdm(infinite(), total=sol_dict['total'])\nfor progress in progress_bar:\n    progress_bar.set_description(f\"Processing {progress}\")", "type_of_change": "argument change", "name_of_class_or_func": "tqdm", "additional_dependencies": ""}
{"python_version": "3.7", "library": "tqdm", "version": "4.29", "problem": "Iterate over an infinite iterable.", "starting_code": "from tqdm import tqdm\n\ndef infinite():\n    i = 0\n    while True:\n        yield i\n        i += 1\n        if i == 1000:\n          return\n\n# Define the total in sol_dict['total'] and use it.\nsol_dict = {\"total\":0}", "example_id": "325", "test": "assert sol_dict['total'] == float('inf')", "solution": "\nsol_dict['total'] = float('inf')\nprogress_bar = tqdm(infinite(), total=sol_dict['total'])\nfor progress in progress_bar:\n    progress_bar.set_description(f\"Processing {progress}\")", "type_of_change": "argument change", "name_of_class_or_func": "tqdm", "additional_dependencies": ""}
{"python_version": "3.7", "library": "kymatio", "version": "0.3.0", "problem": "Implement the function to define and run a 2d scattering transform in Torch. Return a tuple of the Scattering object and the result of Scattering on a.", "starting_code": "import kymatio\nimport torch\nfrom kymatio import Scattering2D\nfrom kymatio.scattering2d.frontend.torch_frontend import ScatteringTorch2D\nfrom typing import Tuple\n\ndef compute_scattering(a: torch.Tensor) -> Tuple[torch.Tensor, ScatteringTorch2D]:\n    ", "example_id": "326", "test": "import kymatio\na = torch.ones((1, 3, 32, 32))\nS, S_a = compute_scattering(a)\nassert isinstance(S_a, torch.Tensor)\nassert isinstance(S, kymatio.scattering2d.frontend.torch_frontend.ScatteringTorch2D)", "solution": "\n\n    S = Scattering2D(2, (32, 32), frontend='torch')\n    S_a = S(a)\n    return S, S_a", "type_of_change": "argument change", "name_of_class_or_func": "Scattering2D", "additional_dependencies": "torch==1.4.0"}
{"python_version": "3.7", "library": "matplotlib", "version": "3.4.0", "problem": "Implement the function to modify the axis of the figure to not visualize ticks on the x and y axis.", "starting_code": "import matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.figure import Figure\nfrom matplotlib.axes import Axes\n\ndef modify(fig: Figure, ax: Axes) -> None:\n    ", "example_id": "327", "test": "import numpy as np \n\nfig, ax = plt.subplots()\nmodify(fig, ax)\n\nassert np.array_equal(ax.get_xticks(), np.array([]))\nassert (ax.get_xticks() == np.array([])).all()\n\nassert np.array_equal(ax.get_xticklabels(), np.array([]))\nassert (ax.get_xticklabels() == np.array([])).all()", "solution": "\n    ax.set_xticks([], minor=False)\n    ax.set_yticks([], minor=False)", "type_of_change": "argument change", "name_of_class_or_func": "matplotlib.pyplot.axis", "additional_dependencies": "numpy==1.18.1 pyparsing==2.3.1 packaging==19.0"}
{"python_version": "3.7", "library": "matplotlib", "version": "3.2.0", "problem": "Implement the function to modify the axis of the figure to not visualize major and minor ticks on the x and y axis, with no labels.", "starting_code": "import matplotlib.pyplot as plt\nfrom matplotlib.figure import Figure\nfrom matplotlib.axes import Axes\n\ndef modify(fig: Figure, ax: Axes) -> None:\n", "example_id": "328", "test": "import numpy as np \n\nfig, ax = plt.subplots()\nmodify(fig, ax)\n\nassert np.array_equal(ax.get_xticks(), np.array([]))\nassert (ax.get_xticks() == np.array([])).all()\n\nassert np.array_equal(ax.get_xticklabels(), np.array([]))\nassert (ax.get_xticklabels() == np.array([])).all()", "solution": "\n    ax.set_xticks([], False)\n    ax.set_yticks([], False)", "type_of_change": "argument change", "name_of_class_or_func": "matplotlib.pyplot.axis", "additional_dependencies": "numpy==1.18.1 pyparsing==2.3.1 packaging==19.0"}
{"python_version": "3.7", "library": "matplotlib", "version": "3.5.0", "problem": "Implement the function to modify the axis of the figure to not visualize major and minor ticks on the x and y axis, with no labels.", "starting_code": "import matplotlib.pyplot as plt\nfrom matplotlib.figure import Figure\nfrom matplotlib.axes import Axes\n\ndef modify(fig: Figure, ax: Axes) -> None:\n", "example_id": "329", "test": "import numpy as np \n\nfig, ax = plt.subplots()\nmodify(fig, ax)\n\nassert np.array_equal(ax.get_xticks(), np.array([]))\nassert (ax.get_xticks() == np.array([])).all()\n\nassert np.array_equal(ax.get_xticklabels(), np.array([]))\nassert (ax.get_xticklabels() == np.array([])).all()", "solution": "\n    ax.set_xticks([], [], minor=False)\n    ax.set_yticks([], [], minor=False)", "type_of_change": "argument change", "name_of_class_or_func": "matplotlib.pyplot.axis", "additional_dependencies": "numpy==1.18.1 pyparsing==2.3.1"}
{"python_version": "3.7", "library": "matplotlib", "version": "3.5.0", "problem": "Implement a function to use Seaborn style.", "starting_code": "import matplotlib.pyplot as plt\n\ndef use_seaborn() -> None:\n    ", "example_id": "330", "test": "use_seaborn()\n\ncycle = plt.rcParams['axes.prop_cycle']\nfrom cycler import cycler\na = cycler('color', ['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974', '#64B5CD'])\nassert cycle==a", "solution": "\n    plt.style.use(\"seaborn\")", "type_of_change": "argument change", "name_of_class_or_func": "matplotlib.pyplot.style.use", "additional_dependencies": "numpy==1.18.1 pyparsing==2.3.1"}
{"python_version": "3.10", "library": "matplotlib", "version": "3.8.0", "problem": "Implement a function to use Seaborn style.", "starting_code": "import matplotlib.pyplot as plt\n\ndef use_seaborn() -> None:\n    ", "example_id": "331", "test": "use_seaborn()\n\ncycle = plt.rcParams['axes.prop_cycle']\nfrom cycler import cycler\na = cycler('color', ['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974', '#64B5CD'])\nassert cycle==a", "solution": "\n    plt.style.use(\"seaborn-v0_8\")\n", "type_of_change": "argument change", "name_of_class_or_func": "matplotlib.pyplot.style.use", "additional_dependencies": "pyparsing==2.3.1"}
